{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2135ac1",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#交叉检验\" data-toc-modified-id=\"交叉检验-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>交叉检验</a></span><ul class=\"toc-item\"><li><span><a href=\"#过拟合\" data-toc-modified-id=\"过拟合-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>过拟合</a></span></li><li><span><a href=\"#k-折交叉检验\" data-toc-modified-id=\"k-折交叉检验-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>k 折交叉检验</a></span><ul class=\"toc-item\"><li><span><a href=\"#scikit-learn的KFold\" data-toc-modified-id=\"scikit-learn的KFold-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>scikit-learn的KFold</a></span></li></ul></li><li><span><a href=\"#分层-k-折交叉检验\" data-toc-modified-id=\"分层-k-折交叉检验-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>分层 k 折交叉检验</a></span></li></ul></li><li><span><a href=\"#模型评估标准\" data-toc-modified-id=\"模型评估标准-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>模型评估标准</a></span><ul class=\"toc-item\"><li><span><a href=\"#准确率\" data-toc-modified-id=\"准确率-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>准确率</a></span></li><li><span><a href=\"#精确率\" data-toc-modified-id=\"精确率-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>精确率</a></span></li><li><span><a href=\"#真阳性率TPR-(灵敏度)\" data-toc-modified-id=\"真阳性率TPR-(灵敏度)-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>真阳性率TPR (灵敏度)</a></span></li><li><span><a href=\"#假阳性率FPR-(特异性或真阴性率或-TNR)\" data-toc-modified-id=\"假阳性率FPR-(特异性或真阴性率或-TNR)-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>假阳性率FPR (特异性或真阴性率或 TNR)</a></span></li><li><span><a href=\"#Precision-Recall曲线\" data-toc-modified-id=\"Precision-Recall曲线-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Precision-Recall曲线</a></span></li><li><span><a href=\"#F1-分数\" data-toc-modified-id=\"F1-分数-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>F1 分数</a></span></li><li><span><a href=\"#ROC-曲线-(以-TPR-为-Y-轴，FPR-为-X-轴)\" data-toc-modified-id=\"ROC-曲线-(以-TPR-为-Y-轴，FPR-为-X-轴)-2.7\"><span class=\"toc-item-num\">2.7&nbsp;&nbsp;</span>ROC 曲线 (以 TPR 为 Y 轴，FPR 为 X 轴)</a></span></li><li><span><a href=\"#对数损失（Logarithmic-Loss，Log-Loss）\" data-toc-modified-id=\"对数损失（Logarithmic-Loss，Log-Loss）-2.8\"><span class=\"toc-item-num\">2.8&nbsp;&nbsp;</span>对数损失（Logarithmic Loss，Log Loss）</a></span></li></ul></li><li><span><a href=\"#混淆矩阵confusion_matrix\" data-toc-modified-id=\"混淆矩阵confusion_matrix-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>混淆矩阵confusion_matrix</a></span></li><li><span><a href=\"#P@K\" data-toc-modified-id=\"P@K-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>P@K</a></span></li><li><span><a href=\"#误差（Error）\" data-toc-modified-id=\"误差（Error）-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>误差（Error）</a></span><ul class=\"toc-item\"><li><span><a href=\"#二次加权卡帕(QWK)\" data-toc-modified-id=\"二次加权卡帕(QWK)-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>二次加权卡帕(QWK)</a></span></li><li><span><a href=\"#马修相关系数（MCC）\" data-toc-modified-id=\"马修相关系数（MCC）-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>马修相关系数（MCC）</a></span></li></ul></li><li><span><a href=\"#超参数优化\" data-toc-modified-id=\"超参数优化-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>超参数优化</a></span><ul class=\"toc-item\"><li><span><a href=\"#GridSearchCV（网格搜索）--模型调参器\" data-toc-modified-id=\"GridSearchCV（网格搜索）--模型调参器-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>GridSearchCV（网格搜索）--模型调参器</a></span></li><li><span><a href=\"#RandomizedSearchCV(随机搜索)\" data-toc-modified-id=\"RandomizedSearchCV(随机搜索)-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>RandomizedSearchCV(随机搜索)</a></span></li><li><span><a href=\"#使用sklearn-optimize库实现超参数\" data-toc-modified-id=\"使用sklearn-optimize库实现超参数-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>使用sklearn-optimize库实现超参数</a></span></li><li><span><a href=\"#超参数优化|随机森林\" data-toc-modified-id=\"超参数优化|随机森林-6.4\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;</span>超参数优化|随机森林</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3f9f66",
   "metadata": {},
   "source": [
    "数据处理归纳"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393bca32",
   "metadata": {},
   "source": [
    "# 交叉检验"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01121b1",
   "metadata": {},
   "source": [
    "## 过拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882af76c",
   "metadata": {},
   "source": [
    "**模型在训练集上完全拟合，而在测试集上却表现不佳**(泛化能力不佳)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3afe99",
   "metadata": {},
   "source": [
    "<img src=\"photos\\overfiting.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a9ce9a",
   "metadata": {},
   "source": [
    "交叉检验有许多不同的方法，它是**建立一个良好的机器学习模型的最关键步骤**。\n",
    "\n",
    "选择正确的交叉检验取决于所处理的数据集，在一个数据集上适用的交叉检验也可能不适用于其他数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1242bc80",
   "metadata": {},
   "source": [
    "## k 折交叉检验"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a16030",
   "metadata": {},
   "source": [
    "将样本和与之相关的目标进行了划分。我们可以将数据分为 **k 个互不关联的不同集合**。这就是所谓的 k 折交叉检验"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952c2e4f",
   "metadata": {},
   "source": [
    "<img src=\"https://ytzfhqs.github.io/AAAMLP-CN/figures/AAAMLP_page21_image_1.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ded6b13",
   "metadata": {},
   "source": [
    "### scikit-learn的KFold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988265c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入 pandas 和 scikit-learn 的 model_selection 模块\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # 训练数据存储在名为 train.csv 的 CSV 文件中\n",
    "    df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "    # 我们创建一个名为 kfold 的新列，并用 -1 填充\n",
    "    df[\"kfold\"] = -1\n",
    "\n",
    "    # 接下来的步骤是随机打乱数据的行\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # 从 model_selection 模块初始化 kfold 类\n",
    "    kf = model_selection.KFold(n_splits=5)\n",
    "\n",
    "    # 填充新的 kfold 列（enumerate的作用是返回一个迭代器）\n",
    "    for fold, (trn_, val_) in enumerate(kf.split(X=df)):\n",
    "        df.loc[val_, 'kfold'] = fold\n",
    "\n",
    "    # 保存带有 kfold 列的新 CSV 文件\n",
    "    df.to_csv(\"train_folds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca75df00",
   "metadata": {},
   "source": [
    "## 分层 k 折交叉检验"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba84c911",
   "metadata": {},
   "source": [
    "如果你有一个偏斜的二元分类数据集，其中正样本占 90%，负样本只占 10%，那么你就不应该使用随机 k 折交叉。\n",
    "\n",
    "对这样的数据集使用简单的 k 折交叉检验可能会导致折叠样本全部为负样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f58edfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入 pandas 和 scikit-learn 的 model_selection 模块\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 训练数据保存在名为 train.csv 的 CSV 文件中\n",
    "    df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "    # 添加一个新列 kfold，并用 -1 初始化\n",
    "    df[\"kfold\"] = -1\n",
    "\n",
    "    # 随机打乱数据行\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # 获取目标变量\n",
    "    y = df.target.values\n",
    "\n",
    "    # 初始化 StratifiedKFold 类，设置折数（folds）为 5\n",
    "    kf = model_selection.StratifiedKFold(n_splits=5)\n",
    "\n",
    "    # 使用 StratifiedKFold 对象的 split 方法来获取训练和验证索引\n",
    "    for f, (t_, v_) in enumerate(kf.split(X=df, y=y)):\n",
    "        df.loc[v_, 'kfold'] = f\n",
    "\n",
    "    # 保存包含 kfold 列的新 CSV 文件\n",
    "    df.to_csv(\"train_folds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7a8179",
   "metadata": {},
   "source": [
    "如果样本量很大（> 10k，> 100k），那么就不需要考虑分层的数量。\n",
    "\n",
    "只需将数据分为 10 或 20 层即可。如果样本数不多，则可以使用 **Sturge's Rule** 这样的简单规则来计算适当的分层数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f872516",
   "metadata": {},
   "source": [
    "**Sturge's Rule**：\n",
    "\n",
    "$NumberofBins = 1+log_2{(N)}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dccb97d",
   "metadata": {},
   "source": [
    "<img src=\"photos\\AAAMLP_image.png\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec4203ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\36085\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# stratified-kfold for regression\n",
    "# 为回归问题进行分层K-折交叉验证\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn import model_selection\n",
    "\n",
    "# 创建分折（folds）的函数\n",
    "def create_folds(data):\n",
    "    # 创建一个新列叫做kfold，并用-1来填充\n",
    "    data[\"kfold\"] = -1\n",
    "\n",
    "    # 随机打乱数据的行\n",
    "    data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # 使用Sturge规则计算bin的数量\n",
    "    num_bins = int(np.floor(1 + np.log2(len(data))))\n",
    "\n",
    "    # 使用pandas的cut函数进行目标变量（target）的分箱\n",
    "    data.loc[:, \"bins\"] = pd.cut(\n",
    "        data[\"target\"], bins=num_bins, labels=False\n",
    "    )\n",
    "\n",
    "    # 初始化StratifiedKFold类\n",
    "    kf = model_selection.StratifiedKFold(n_splits=5)\n",
    "\n",
    "    # 填充新的kfold列\n",
    "    # 注意：我们使用的是bins而不是实际的目标变量（target）！\n",
    "    for f, (t_, v_) in enumerate(kf.split(X=data, y=data.bins.values)):\n",
    "        data.loc[v_, 'kfold'] = f\n",
    "\n",
    "    # 删除bins列\n",
    "    data = data.drop(\"bins\", axis=1)\n",
    "\n",
    "    # 返回包含folds的数据\n",
    "    return data\n",
    "\n",
    "\n",
    "# 主程序开始\n",
    "if __name__ == \"__main__\":\n",
    "    # 创建一个带有15000个样本、100个特征和1个目标变量的样本数据集\n",
    "    X, y = datasets.make_regression(n_samples=15000, n_features=100, n_targets=1)\n",
    "    \n",
    "    # 使用numpy数组创建一个数据框\n",
    "    df = pd.DataFrame(X, columns=[f\"f_{i}\" for i in range(X.shape[1])]\n",
    "    )\n",
    "    df.loc[:, \"target\"] = y\n",
    "\n",
    "    # 创建folds\n",
    "    df = create_folds(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e13085b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>f_9</th>\n",
       "      <th>...</th>\n",
       "      <th>f_92</th>\n",
       "      <th>f_93</th>\n",
       "      <th>f_94</th>\n",
       "      <th>f_95</th>\n",
       "      <th>f_96</th>\n",
       "      <th>f_97</th>\n",
       "      <th>f_98</th>\n",
       "      <th>f_99</th>\n",
       "      <th>target</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.823957</td>\n",
       "      <td>0.207763</td>\n",
       "      <td>-0.394248</td>\n",
       "      <td>0.507653</td>\n",
       "      <td>1.253423</td>\n",
       "      <td>1.778465</td>\n",
       "      <td>-0.256689</td>\n",
       "      <td>-1.831634</td>\n",
       "      <td>0.525332</td>\n",
       "      <td>0.456641</td>\n",
       "      <td>...</td>\n",
       "      <td>1.947085</td>\n",
       "      <td>-0.265704</td>\n",
       "      <td>-0.556624</td>\n",
       "      <td>0.975684</td>\n",
       "      <td>-0.386927</td>\n",
       "      <td>-0.816603</td>\n",
       "      <td>-0.990812</td>\n",
       "      <td>0.104352</td>\n",
       "      <td>-345.824560</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.863406</td>\n",
       "      <td>-0.168406</td>\n",
       "      <td>1.856114</td>\n",
       "      <td>0.189797</td>\n",
       "      <td>-0.090543</td>\n",
       "      <td>-0.620822</td>\n",
       "      <td>0.515979</td>\n",
       "      <td>-0.289214</td>\n",
       "      <td>0.956292</td>\n",
       "      <td>-1.583018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.594500</td>\n",
       "      <td>-0.571906</td>\n",
       "      <td>-0.911507</td>\n",
       "      <td>1.301424</td>\n",
       "      <td>0.462511</td>\n",
       "      <td>1.168068</td>\n",
       "      <td>0.193584</td>\n",
       "      <td>1.160058</td>\n",
       "      <td>233.557718</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.037843</td>\n",
       "      <td>0.860436</td>\n",
       "      <td>-0.596053</td>\n",
       "      <td>1.195143</td>\n",
       "      <td>-1.942161</td>\n",
       "      <td>0.279118</td>\n",
       "      <td>-0.070356</td>\n",
       "      <td>-0.041443</td>\n",
       "      <td>1.817803</td>\n",
       "      <td>0.433958</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.229399</td>\n",
       "      <td>1.307245</td>\n",
       "      <td>0.399088</td>\n",
       "      <td>-0.462973</td>\n",
       "      <td>0.559238</td>\n",
       "      <td>0.077918</td>\n",
       "      <td>-0.873975</td>\n",
       "      <td>0.625772</td>\n",
       "      <td>214.385153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.240865</td>\n",
       "      <td>0.010202</td>\n",
       "      <td>0.195245</td>\n",
       "      <td>-0.817007</td>\n",
       "      <td>1.023410</td>\n",
       "      <td>0.320102</td>\n",
       "      <td>2.238255</td>\n",
       "      <td>1.123633</td>\n",
       "      <td>-0.748968</td>\n",
       "      <td>-0.030394</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.446081</td>\n",
       "      <td>-0.184762</td>\n",
       "      <td>0.336858</td>\n",
       "      <td>1.366016</td>\n",
       "      <td>-0.302969</td>\n",
       "      <td>-0.411445</td>\n",
       "      <td>0.283740</td>\n",
       "      <td>0.216146</td>\n",
       "      <td>-40.122136</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.994406</td>\n",
       "      <td>-0.424863</td>\n",
       "      <td>0.256059</td>\n",
       "      <td>-0.762410</td>\n",
       "      <td>1.238615</td>\n",
       "      <td>-0.183485</td>\n",
       "      <td>1.167865</td>\n",
       "      <td>0.459609</td>\n",
       "      <td>0.593771</td>\n",
       "      <td>-0.362750</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.209369</td>\n",
       "      <td>2.461145</td>\n",
       "      <td>1.024259</td>\n",
       "      <td>-1.363809</td>\n",
       "      <td>-0.915053</td>\n",
       "      <td>0.896689</td>\n",
       "      <td>1.533087</td>\n",
       "      <td>-0.508177</td>\n",
       "      <td>68.974958</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>-0.559569</td>\n",
       "      <td>0.296765</td>\n",
       "      <td>0.364212</td>\n",
       "      <td>0.972185</td>\n",
       "      <td>-0.242776</td>\n",
       "      <td>0.624846</td>\n",
       "      <td>1.717548</td>\n",
       "      <td>0.977617</td>\n",
       "      <td>1.074662</td>\n",
       "      <td>-1.475026</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.252428</td>\n",
       "      <td>1.260867</td>\n",
       "      <td>0.185563</td>\n",
       "      <td>0.762149</td>\n",
       "      <td>-1.181457</td>\n",
       "      <td>-0.356687</td>\n",
       "      <td>-1.366169</td>\n",
       "      <td>-0.598961</td>\n",
       "      <td>174.834838</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>0.523120</td>\n",
       "      <td>0.296157</td>\n",
       "      <td>1.861660</td>\n",
       "      <td>-0.046944</td>\n",
       "      <td>0.219107</td>\n",
       "      <td>0.329624</td>\n",
       "      <td>-1.103541</td>\n",
       "      <td>-1.009707</td>\n",
       "      <td>0.885294</td>\n",
       "      <td>-1.717296</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.179742</td>\n",
       "      <td>-0.313219</td>\n",
       "      <td>1.007597</td>\n",
       "      <td>-0.957590</td>\n",
       "      <td>-0.388035</td>\n",
       "      <td>-0.164138</td>\n",
       "      <td>0.434777</td>\n",
       "      <td>0.851730</td>\n",
       "      <td>-114.356010</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>0.273997</td>\n",
       "      <td>-1.950455</td>\n",
       "      <td>0.169383</td>\n",
       "      <td>0.314692</td>\n",
       "      <td>-0.710891</td>\n",
       "      <td>-1.513990</td>\n",
       "      <td>0.303446</td>\n",
       "      <td>-0.162371</td>\n",
       "      <td>-0.803209</td>\n",
       "      <td>0.604601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.413240</td>\n",
       "      <td>0.042272</td>\n",
       "      <td>-0.980795</td>\n",
       "      <td>-0.672659</td>\n",
       "      <td>-1.150833</td>\n",
       "      <td>-0.084720</td>\n",
       "      <td>-0.062419</td>\n",
       "      <td>0.986816</td>\n",
       "      <td>195.385245</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>0.752473</td>\n",
       "      <td>0.836822</td>\n",
       "      <td>2.016183</td>\n",
       "      <td>1.214802</td>\n",
       "      <td>-0.291490</td>\n",
       "      <td>1.047437</td>\n",
       "      <td>-0.761860</td>\n",
       "      <td>0.597998</td>\n",
       "      <td>-0.935403</td>\n",
       "      <td>-1.626731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379246</td>\n",
       "      <td>1.342065</td>\n",
       "      <td>-0.805945</td>\n",
       "      <td>0.343068</td>\n",
       "      <td>-1.590127</td>\n",
       "      <td>-1.541754</td>\n",
       "      <td>1.037647</td>\n",
       "      <td>1.332851</td>\n",
       "      <td>93.274045</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>-0.711117</td>\n",
       "      <td>-0.811922</td>\n",
       "      <td>-0.028847</td>\n",
       "      <td>0.479169</td>\n",
       "      <td>-0.035734</td>\n",
       "      <td>-0.512273</td>\n",
       "      <td>-0.971491</td>\n",
       "      <td>-0.878834</td>\n",
       "      <td>-0.826218</td>\n",
       "      <td>0.670823</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.170690</td>\n",
       "      <td>-1.781461</td>\n",
       "      <td>1.392503</td>\n",
       "      <td>0.329878</td>\n",
       "      <td>0.025079</td>\n",
       "      <td>1.378049</td>\n",
       "      <td>0.362354</td>\n",
       "      <td>-0.065309</td>\n",
       "      <td>-410.426878</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            f_0       f_1       f_2       f_3       f_4       f_5       f_6  \\\n",
       "0     -0.823957  0.207763 -0.394248  0.507653  1.253423  1.778465 -0.256689   \n",
       "1      1.863406 -0.168406  1.856114  0.189797 -0.090543 -0.620822  0.515979   \n",
       "2     -0.037843  0.860436 -0.596053  1.195143 -1.942161  0.279118 -0.070356   \n",
       "3      0.240865  0.010202  0.195245 -0.817007  1.023410  0.320102  2.238255   \n",
       "4      0.994406 -0.424863  0.256059 -0.762410  1.238615 -0.183485  1.167865   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "14995 -0.559569  0.296765  0.364212  0.972185 -0.242776  0.624846  1.717548   \n",
       "14996  0.523120  0.296157  1.861660 -0.046944  0.219107  0.329624 -1.103541   \n",
       "14997  0.273997 -1.950455  0.169383  0.314692 -0.710891 -1.513990  0.303446   \n",
       "14998  0.752473  0.836822  2.016183  1.214802 -0.291490  1.047437 -0.761860   \n",
       "14999 -0.711117 -0.811922 -0.028847  0.479169 -0.035734 -0.512273 -0.971491   \n",
       "\n",
       "            f_7       f_8       f_9  ...      f_92      f_93      f_94  \\\n",
       "0     -1.831634  0.525332  0.456641  ...  1.947085 -0.265704 -0.556624   \n",
       "1     -0.289214  0.956292 -1.583018  ...  0.594500 -0.571906 -0.911507   \n",
       "2     -0.041443  1.817803  0.433958  ... -0.229399  1.307245  0.399088   \n",
       "3      1.123633 -0.748968 -0.030394  ... -1.446081 -0.184762  0.336858   \n",
       "4      0.459609  0.593771 -0.362750  ... -0.209369  2.461145  1.024259   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "14995  0.977617  1.074662 -1.475026  ... -1.252428  1.260867  0.185563   \n",
       "14996 -1.009707  0.885294 -1.717296  ... -1.179742 -0.313219  1.007597   \n",
       "14997 -0.162371 -0.803209  0.604601  ...  0.413240  0.042272 -0.980795   \n",
       "14998  0.597998 -0.935403 -1.626731  ...  0.379246  1.342065 -0.805945   \n",
       "14999 -0.878834 -0.826218  0.670823  ... -1.170690 -1.781461  1.392503   \n",
       "\n",
       "           f_95      f_96      f_97      f_98      f_99      target  kfold  \n",
       "0      0.975684 -0.386927 -0.816603 -0.990812  0.104352 -345.824560      0  \n",
       "1      1.301424  0.462511  1.168068  0.193584  1.160058  233.557718      0  \n",
       "2     -0.462973  0.559238  0.077918 -0.873975  0.625772  214.385153      0  \n",
       "3      1.366016 -0.302969 -0.411445  0.283740  0.216146  -40.122136      0  \n",
       "4     -1.363809 -0.915053  0.896689  1.533087 -0.508177   68.974958      0  \n",
       "...         ...       ...       ...       ...       ...         ...    ...  \n",
       "14995  0.762149 -1.181457 -0.356687 -1.366169 -0.598961  174.834838      4  \n",
       "14996 -0.957590 -0.388035 -0.164138  0.434777  0.851730 -114.356010      4  \n",
       "14997 -0.672659 -1.150833 -0.084720 -0.062419  0.986816  195.385245      4  \n",
       "14998  0.343068 -1.590127 -1.541754  1.037647  1.332851   93.274045      4  \n",
       "14999  0.329878  0.025079  1.378049  0.362354 -0.065309 -410.426878      4  \n",
       "\n",
       "[15000 rows x 102 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d430d63",
   "metadata": {},
   "source": [
    "交叉检验是构建机器学习模型的第一步，也是最基本的一步。\n",
    "\n",
    "如果要做特征工程，首先要拆分数据。如果要建立模型，首先要拆分数据。\n",
    "\n",
    "如果你有一个好的交叉检验方案，其中验证数据能够代表训练数据和真实世界的数据，那么你就能建立一个具有高度通用性的好的机器学习模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec3ef09",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b52b737",
   "metadata": {},
   "source": [
    "# 模型评估标准"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5021fa9a",
   "metadata": {},
   "source": [
    "在**二元分类指标**中，当正负样本数量相等时，我们通常使用 **准确率、精确率、召回率 和 F1**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85feb7c6",
   "metadata": {},
   "source": [
    "## 准确率\n",
    "---\n",
    "机器学习中最直接的指标之一。它定义了模型的准确度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29354ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "l1 = [0,1,1,1,0,0,0,1]\n",
    "l2 = [0,1,0,1,0,1,0,0]\n",
    "\n",
    "metrics.accuracy_score(l1, l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b965f170",
   "metadata": {},
   "source": [
    "对于accuracy指标**一个类别中的样本数量比另一个类别中的样本数量多很多。**\n",
    "\n",
    "在这种情况下，使用准确率作为评估指标是不可取的，因为它不能代表数据。\n",
    "\n",
    "因此，您可能会获得很高的准确率，但您的模型在实际样本中的表现可能并不理想，而且您也无法解释原因"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c1a4ee",
   "metadata": {},
   "source": [
    "## 精确率"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764abe7b",
   "metadata": {},
   "source": [
    "- 真阳性 （TP）:正确预测了阳性类别\n",
    "- 真阴性 （TN）:准确预测了阴性类别\n",
    "- 假阳性 （FP）:错误地（或虚假地）预测了阳性类\n",
    "- 假阴性 （FN）:错误地（或虚假地）预测了阴性类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23dcc165",
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_positive(y_true, y_pred):\n",
    "    # 初始化真阳性样本计数器\n",
    "    tp = 0\n",
    "    # 遍历y_true，y_pred中所有元素\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        # 若真实标签为正类且预测标签也为正类，计数器增加\n",
    "        if yt == 1 and yp == 1:\n",
    "            tp += 1\n",
    "    # 返回真阳性样本数\n",
    "    return tp\n",
    "#-----------------------------------------------------------\n",
    "def true_negative(y_true, y_pred):\n",
    "    # 初始化真阴性样本计数器\n",
    "    tn = 0\n",
    "    # 遍历y_true，y_pred中所有元素\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "         # 若真实标签为负类且预测标签也为负类，计数器增加\n",
    "        if yt == 0 and yp == 0:\n",
    "            tn += 1\n",
    "    # 返回真阴性样本数\n",
    "    return tn\n",
    "#-----------------------------------------------------------\n",
    "def false_positive(y_true, y_pred):\n",
    "    # 初始化假阳性计数器\n",
    "    fp = 0\n",
    "    # 遍历y_true，y_pred中所有元素\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        # 若真实标签为负类而预测标签为正类，计数器增加\n",
    "        if yt == 0 and yp == 1:\n",
    "            fp += 1\n",
    "    # 返回假阳性样本数\n",
    "    return fp\n",
    "#-----------------------------------------------------------\n",
    "def false_negative(y_true, y_pred):\n",
    "    # 初始化假阴性计数器\n",
    "    fn = 0\n",
    "    # 遍历y_true，y_pred中所有元素\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        # 若真实标签为正类而预测标签为负类，计数器增加\n",
    "        if yt == 1 and yp == 0:\n",
    "            fn += 1\n",
    "    # 返回假阴性数\n",
    "    return fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdbecdc",
   "metadata": {},
   "source": [
    "<img src=\"photos\\tp.png\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1443bff0",
   "metadata": {},
   "source": [
    "- **准确率**:\n",
    "\n",
    "$AccuracyScore=(TP+TN) / (TP+TN+FP+FN)$\n",
    "\n",
    "- **精确率**:\n",
    "\n",
    "$Precision=TP / (TP+FP)$\n",
    "\n",
    "- **召回率**:\n",
    "\n",
    "$Recall=TP / (TP+FN)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ef163d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    # 真阳性样本数\n",
    "    tp = true_positive(y_true, y_pred)\n",
    "    # 假阳性样本数\n",
    "    fp = false_positive(y_true, y_pred)\n",
    "    # 精确率\n",
    "    precision = tp / (tp + fp)\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    # 真阳性样本数\n",
    "    tp = true_positive(y_true, y_pred)\n",
    "    # 假阴性样本数\n",
    "    fn = false_negative(y_true, y_pred)\n",
    "    # 召回率\n",
    "    recall = tp / (tp + fn)\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fd2d35",
   "metadata": {},
   "source": [
    "**对于一个 \"好 \"模型来说，精确率和召回值都应该很高**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4edb97",
   "metadata": {},
   "source": [
    "<img src=\"photos\\c7efe4ff758b4937877ade0abf004095.png\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420a1704",
   "metadata": {},
   "source": [
    "## 真阳性率TPR (灵敏度)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031ca802",
   "metadata": {},
   "source": [
    "$TPR=TP / (TP+FN)$  **与召回率相同**:敏感性又称真阳性率，就是发病之后，你的诊断方法对疾病的敏感程度（识别能力）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ed542ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tpr(y_true, y_pred):\n",
    "    # 真阳性率（TPR），与召回率计算公式一致\n",
    "    return recall(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d40c44",
   "metadata": {},
   "source": [
    "TPR 或召回率也被称为灵敏度。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41534072",
   "metadata": {},
   "source": [
    "## 假阳性率FPR (特异性或真阴性率或 TNR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e044a3e3",
   "metadata": {},
   "source": [
    "$FPR=FP / (TN+FP)$:不发病（我们这里称之为健康）的特征是有别于发病的特征的，我们利用这些差异避免误诊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "15c35207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fpr(y_true, y_pred):\n",
    "    # 假阳性样本数\n",
    "    fp = false_positive(y_true, y_pred)\n",
    "    # 真阴性样本数\n",
    "    tn = true_negative(y_true, y_pred)\n",
    "# 返回假阳性率（FPR）\n",
    "    return fp / (tn + fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6957bb",
   "metadata": {},
   "source": [
    "## Precision-Recall曲线\n",
    "---\n",
    "当我们希望分类结果的精准率、召回率或者精准率和召回率两个指标在某些指定值上时，就可以通过这种方式来找到对应横坐标上的阈值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b12ceb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions = []\n",
    "recalls = []\n",
    "y_true = [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
    "y_pred = [0.02638412, 0.11114267, 0.31620708,0.0490937, 0.0191491, 0.17554844,0.15952202, 0.03819563, 0.11639273,0.079377,  0.08584789, 0.39095342, 0.27259048, 0.03447096, 0.04644807,0.03543574, 0.18521942, 0.05934905,0.61977213, 0.33056815]\n",
    "thresholds = [0.0490937 , 0.05934905, 0.079377,\n",
    "              0.08584789, 0.11114267, 0.11639273,\n",
    "              0.15952202, 0.17554844, 0.18521942,\n",
    "              0.27259048, 0.31620708, 0.33056815,\n",
    "              0.39095342, 0.61977213]\n",
    "\n",
    "# 遍历预测阈值\n",
    "for i in thresholds:\n",
    "    # 若样本为正类（1）的概率大于阈值，为1，否则为0\n",
    "    temp_prediction = [1 if x >= i else 0 for x in y_pred]\n",
    "    # 计算精确率\n",
    "    p = precision(y_true, temp_prediction)\n",
    "    # 计算召回率\n",
    "    r = recall(y_true, temp_prediction)\n",
    "    # 加入精确率列表\n",
    "    precisions.append(p)\n",
    "    # 加入召回率列表\n",
    "    recalls.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e10a25d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Precision')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 创建画布\n",
    "plt.figure(figsize=(7, 7))\n",
    "# x轴为召回率，y轴为精确率\n",
    "plt.plot(recalls, precisions)\n",
    "# 添加x轴标签，字体大小为15\n",
    "plt.xlabel('Recall', fontsize=15)\n",
    "# 添加y轴标签，字条大小为15\n",
    "plt.ylabel('Precision', fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3073e3",
   "metadata": {},
   "source": [
    "## F1 分数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc25707b",
   "metadata": {},
   "source": [
    "**f1-score是精确率和召回率的综合指标**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b1bbc3",
   "metadata": {},
   "source": [
    "$F1=2PR / (P+R)$\n",
    "或: $F1=2TP/(2TP+FP+FN)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05fbc8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    # 计算精确率\n",
    "    p = precision(y_true, y_pred)\n",
    "    # 计算召回率\n",
    "    r = recall(y_true, y_pred)\n",
    "    # 计算f1值\n",
    "    score = 2 * p * r / (p + r)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3656cf57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5714285714285715"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = [0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
    "         1, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
    "y_pred = [0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
    "         1, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "metrics.f1_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28d7b8c",
   "metadata": {},
   "source": [
    "## ROC 曲线 (以 TPR 为 Y 轴，FPR 为 X 轴)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e626d46b",
   "metadata": {},
   "source": [
    "ROC 曲线下面积或曲线下面积，简称 **AUC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8d18c18b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ee4c925ad0>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 初始化真阳性率列表\n",
    "tpr_list = []\n",
    "# 初始化假阳性率列表\n",
    "fpr_list = []\n",
    "\n",
    "# 真实样本标签\n",
    "y_true = [0, 0, 0, 0, 1, 0, 1,\n",
    "          0, 0, 1, 0, 1, 0, 0, 1]\n",
    "\n",
    "# 预测样本为正类（1）的概率\n",
    "y_pred = [0.1, 0.3, 0.2, 0.6, 0.8, 0.05,\n",
    "          0.9, 0.5, 0.3, 0.66, 0.3, 0.2,\n",
    "          0.85, 0.15, 0.99]\n",
    "\n",
    "# 预测阈值\n",
    "thresholds = [0, 0.1, 0.2, 0.3, 0.4, 0.5,\n",
    "              0.6, 0.7, 0.8, 0.85, 0.9, 0.99, 1.0]\n",
    "\n",
    "# 遍历预测阈值\n",
    "for thresh in thresholds:\n",
    "    # 若样本为正类（1）的概率大于阈值，为1，否则为0\n",
    "    temp_pred = [1 if x >= thresh else 0 for x in y_pred]\n",
    "    # 真阳性率\n",
    "    temp_tpr = tpr(y_true, temp_pred)\n",
    "    # 假阳性率\n",
    "    temp_fpr = fpr(y_true, temp_pred)\n",
    "    # 将真阳性率加入列表\n",
    "    tpr_list.append(temp_tpr)\n",
    "    # 将假阳性率加入列表\n",
    "    fpr_list.append(temp_fpr)\n",
    "    \n",
    "plt.plot(fpr_list, tpr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d15a7a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8300000000000001"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "y_true = [0, 0, 0, 0, 1, 0, 1,\n",
    "         0, 0, 1, 0, 1, 0, 0, 1]\n",
    "y_pred = [0.1, 0.3, 0.2, 0.6, 0.8, 0.05, 0.9, 0.5, 0.3, 0.66, 0.3, 0.2, 0.85, 0.15, 0.99]\n",
    "metrics.roc_auc_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3a8e00",
   "metadata": {},
   "source": [
    "**AUC 值从 0 到 1 不等。**\n",
    "\n",
    "* AUC = 1 意味着拥有一个完美的模型。大多数情况下，这意味着你在验证时犯了一些错误，应该重新审视数据处理和验证流程。如果你没有犯任何错误，那么恭喜你，你已经拥有了针对数据集建立的最佳模型。\n",
    "* AUC = 0 意味着您的模型非常糟糕（或非常好！）。试着反转预测的概率，例如，如果您预测正类的概率是 p，试着用 1-p 代替它。这种 AUC 也可能意味着您的验证或数据处理存在问题。\n",
    "* AUC = 0.5 意味着你的预测是随机的。因此，对于任何二元分类问题，如果我将所有目标都预测为 0.5，我将得到 0.5 的 AUC。\n",
    "* AUC 值介于 0 和 0.5 之间，意味着你的模型比随机模型更差。大多数情况下，这是因为你颠倒了类别。 如果您尝试反转预测，您的 AUC 值可能会超过 0.5。接近 1 的 AUC 值被认为是好值。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79172d2",
   "metadata": {},
   "source": [
    "<img src=\"photos\\kisss.png\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d401443",
   "metadata": {},
   "source": [
    "## 对数损失（Logarithmic Loss，Log Loss）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198369b4",
   "metadata": {},
   "source": [
    "$LogLoss=−1.0×(target×log(prediction)+(1−target)×log(1−prediction))$\n",
    "\n",
    "**目标值为 0 或 1，预测值为样本属于类别 1 的概率**\n",
    "\n",
    "对数损失会对不正确或偏差较大的预测进行相当高的惩罚，也就是说，对数损失会对非常确定和非常错误的预测进行惩罚\n",
    "\n",
    "**对数损失的惩罚要比其他指标大得多**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1a997dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49882711861432294"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y_true = [0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1]\n",
    "y_proba = [0.1, 0.3, 0.2, 0.6, 0.8, 0.05, 0.9, 0.5, 0.3, 0.66, 0.3, 0.2, 0.85, 0.15, 0.99]\n",
    "\n",
    "metrics.log_loss(y_true, y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c294f599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39814814814814814"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "y_true = [0, 1, 2, 0, 1, 2, 0, 2, 2]\n",
    "y_pred = [0, 2, 1, 0, 2, 1, 0, 0, 2]\n",
    "# 宏观平均精确率\n",
    "metrics.precision_score(y_true, y_pred, average=\"macro\")   \n",
    "# 微观平均精确率\n",
    "metrics.precision_score(y_true, y_pred, average=\"micro\")\n",
    "# 加权精确率\n",
    "metrics.precision_score(y_true, y_pred, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e576311b",
   "metadata": {},
   "source": [
    "# 混淆矩阵confusion_matrix\n",
    "---\n",
    "使用混淆矩阵，您可以快速查看有多少样本被错误分类，有多少样本被正确分类。也许有人会说"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc326a4c",
   "metadata": {},
   "source": [
    "**二元混淆矩阵是一个包含 TP、FP、TN 和 FN 的表格**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ddd35a",
   "metadata": {},
   "source": [
    "<img src=\"photos\\AAAMLP_hunxiao.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f71fbdeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 57.249999999999986, 'Predicted Labels')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "\n",
    "# 真实样本标签\n",
    "y_true = [0, 1, 2, 0, 1, 2, 0, 2, 2]\n",
    "# 预测样本标签\n",
    "y_pred = [0, 2, 1, 0, 2, 1, 0, 0, 2]\n",
    "\n",
    "# 计算混淆矩阵\n",
    "cm = metrics.confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# 创建画布\n",
    "plt.figure(figsize=(10, 10))\n",
    "# 创建方格\n",
    "cmap = sns.cubehelix_palette(50, hue=0.05, rot=0, light=0.9, dark=0,\n",
    "as_cmap=True)\n",
    "# 规定字体大小\n",
    "sns.set(font_scale=2.5)\n",
    "# 绘制热图\n",
    "sns.heatmap(cm, annot=True, cmap=cmap, cbar=False)\n",
    "# y轴标签，字体大小为20\n",
    "plt.ylabel('Actual Labels', fontsize=20)\n",
    "# x轴标签，字体大小为20\n",
    "plt.xlabel('Predicted Labels', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c97c02",
   "metadata": {},
   "source": [
    "# P@K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f4fe57",
   "metadata": {},
   "source": [
    "- P@K 代表前 K 个预测值中有多少的准确率 (Precision)\n",
    "- AP@k  average precision 的缩写，计算方式是把所有相关文档的 P@K 求平均。\n",
    "- MAP@k MAP 是 mean average precision 的缩写，就是把所有的 AP 求平均\n",
    "\n",
    "**P@k、AP@k 和 MAP@k 的范围都是从 0 到 1，其中 1 为最佳。**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1fc1bd",
   "metadata": {},
   "source": [
    "# 误差（Error）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cf81ea",
   "metadata": {},
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56778a67",
   "metadata": {},
   "source": [
    "$Error=True Value−Predicted Value$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f3d0e0",
   "metadata": {},
   "source": [
    "绝对误差（Absolute error）只是上述误差的绝对值\n",
    "\n",
    "$Absolute Error=Abs(True Value−Predicted Value)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a714d647",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48ef979",
   "metadata": {},
   "source": [
    "**平均绝对误差（MAE）**。它只是所有绝对误差的平均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef07518",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb21a5ea",
   "metadata": {},
   "source": [
    "**均方误差 （MSE）** $Squared Error=(TrueValue−Predicted Value) \n",
    "2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f852bde",
   "metadata": {},
   "source": [
    "**RMSE（均方根误差）**是评估回归模型最常用的指标:\n",
    "\n",
    "$RMSE=SQRT(MSE)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eab9b66",
   "metadata": {},
   "source": [
    "回归指标 $R^2$（R 方），也称为判定系数\n",
    "\n",
    "**R方表示模型与数据的拟合程度。R 方接近 1.0 表示模型与数据的拟合程度相当好，而接近 0 则表示模型不是那么好。当模型只是做出荒谬的预测时，R 方也可能是负值**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315febf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3d13a0",
   "metadata": {},
   "source": [
    "## 二次加权卡帕(QWK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f150e115",
   "metadata": {},
   "source": [
    "QWK 衡量两个 \"评分 \"之间的 \"一致性\"。评分可以是 0 到 N 之间的任何实数，预测也在同一范围内。\n",
    "\n",
    "一致性可以定义为这些评级之间的接近程度。因此，它适用于有 N 个不同类别的分类问题。**如果一致度高，分数就更接近 1.0**\n",
    "\n",
    "(QWK 大于 0.85 即为非常好)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5ea132a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33333333333333337"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y_true = [1, 2, 3, 1, 2, 3, 1, 2, 3]\n",
    "y_pred = [2, 1, 3, 1, 2, 3, 3, 1, 2]\n",
    "\n",
    "metrics.cohen_kappa_score(y_true, y_pred, weights=\"quadratic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1210cae8",
   "metadata": {},
   "source": [
    "## 马修相关系数（MCC）\n",
    "---\n",
    "是一种常用于评估分类模型性能的指标。它可以衡量模型的真实预测情况，不受样本不平衡影响，取值范围从-1到1，值越大表示模型性能越好"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ee74b4",
   "metadata": {},
   "source": [
    "MCC = (TP * TN - FP * FN) / sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n",
    "\n",
    "1 代表完美预测，-1 代表不完美预测，0 代表随机预测。\n",
    "\n",
    "**通常情况下，MCC值在0.5以上被认为是一个较好的分类模型，而大于0.7则表示模型具有很高的准确性。实际上，一个最好的模型应该不只是MCC高，还应该考虑其他指标，如准确率、召回率、F1-score等，以便全面地评估模型性能表现。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dcd76535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "y_true = [0, 1, 0, 0, 1]\n",
    "y_pred = [0, 1, 1, 0, 0]\n",
    "\n",
    "mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "print(mcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7159c5bc",
   "metadata": {},
   "source": [
    "在样本数量较少的情况下，可能会出现预测波动大的情况，这也意味着MCC值可能会受随机性影响，因此，当样本量不足时，需要谨慎使用MCC指标。\n",
    "\n",
    "另外，当两个类别中的样本数量存在明显差异时，MCC值的稳定性也会受到影响"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83de5dd5",
   "metadata": {},
   "source": [
    "# 超参数优化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb314dc",
   "metadata": {},
   "source": [
    "**超参数迭代训练**\n",
    "```\n",
    "# 初始化最佳准确度\n",
    "best_accuracy = 0\n",
    "# 初始化最佳参数的字典\n",
    "best_parameters = {\"a\": 0, \"b\": 0, \"c\": 0} \n",
    "# 循环遍历 a 的取值范围 1~10\n",
    "for a in range(1, 11):\n",
    "    # 循环遍历 b 的取值范围 1~10\n",
    "    for b in range(1, 11):\n",
    "        # 循环遍历 c 的取值范围 1~10\n",
    "        for c in range(1, 11):\n",
    "            # 创建模型，使用 a、b、c 参数\n",
    "            model = MODEL(a, b, c)\n",
    "            # 使用训练数据拟合模型\n",
    "            model.fit(training_data)\n",
    "            # 使用模型对验证数据进行预测\n",
    "            preds = model.predict(validation_data)\n",
    "            # 计算预测的准确度\n",
    "            accuracy = metrics.accuracy_score(targets, preds)\n",
    "             # 如果当前准确度优于之前的最佳准确度，则更新最佳准确度和最佳参数\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy \n",
    "                best_parameters[\"a\"] = a\n",
    "                best_parameters[\"b\"] = b \n",
    "                best_parameters[\"c\"] = c\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f228760d",
   "metadata": {},
   "source": [
    ">但是要将所有这些参数的所有组合全部穷尽是不可能的"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c955a9c",
   "metadata": {},
   "source": [
    "## GridSearchCV（网格搜索）--模型调参器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b8d78a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "[CV 1/5; 1/72] START criterion=gini, max_depth=1, n_estimators=100..............\n",
      "[CV 1/5; 1/72] END criterion=gini, max_depth=1, n_estimators=100;, score=0.540 total time=   3.1s\n",
      "[CV 2/5; 1/72] START criterion=gini, max_depth=1, n_estimators=100..............\n",
      "[CV 2/5; 1/72] END criterion=gini, max_depth=1, n_estimators=100;, score=0.618 total time=   0.0s\n",
      "[CV 3/5; 1/72] START criterion=gini, max_depth=1, n_estimators=100..............\n",
      "[CV 3/5; 1/72] END criterion=gini, max_depth=1, n_estimators=100;, score=0.613 total time=   0.0s\n",
      "[CV 4/5; 1/72] START criterion=gini, max_depth=1, n_estimators=100..............\n",
      "[CV 4/5; 1/72] END criterion=gini, max_depth=1, n_estimators=100;, score=0.578 total time=   0.0s\n",
      "[CV 5/5; 1/72] START criterion=gini, max_depth=1, n_estimators=100..............\n",
      "[CV 5/5; 1/72] END criterion=gini, max_depth=1, n_estimators=100;, score=0.552 total time=   0.0s\n",
      "[CV 1/5; 2/72] START criterion=gini, max_depth=1, n_estimators=200..............\n",
      "[CV 1/5; 2/72] END criterion=gini, max_depth=1, n_estimators=200;, score=0.590 total time=   0.1s\n",
      "[CV 2/5; 2/72] START criterion=gini, max_depth=1, n_estimators=200..............\n",
      "[CV 2/5; 2/72] END criterion=gini, max_depth=1, n_estimators=200;, score=0.575 total time=   0.1s\n",
      "[CV 3/5; 2/72] START criterion=gini, max_depth=1, n_estimators=200..............\n",
      "[CV 3/5; 2/72] END criterion=gini, max_depth=1, n_estimators=200;, score=0.615 total time=   0.1s\n",
      "[CV 4/5; 2/72] START criterion=gini, max_depth=1, n_estimators=200..............\n",
      "[CV 4/5; 2/72] END criterion=gini, max_depth=1, n_estimators=200;, score=0.525 total time=   0.1s\n",
      "[CV 5/5; 2/72] START criterion=gini, max_depth=1, n_estimators=200..............\n",
      "[CV 5/5; 2/72] END criterion=gini, max_depth=1, n_estimators=200;, score=0.583 total time=   0.1s\n",
      "[CV 1/5; 3/72] START criterion=gini, max_depth=1, n_estimators=250..............\n",
      "[CV 1/5; 3/72] END criterion=gini, max_depth=1, n_estimators=250;, score=0.570 total time=   0.1s\n",
      "[CV 2/5; 3/72] START criterion=gini, max_depth=1, n_estimators=250..............\n",
      "[CV 2/5; 3/72] END criterion=gini, max_depth=1, n_estimators=250;, score=0.608 total time=   0.1s\n",
      "[CV 3/5; 3/72] START criterion=gini, max_depth=1, n_estimators=250..............\n",
      "[CV 3/5; 3/72] END criterion=gini, max_depth=1, n_estimators=250;, score=0.603 total time=   0.1s\n",
      "[CV 4/5; 3/72] START criterion=gini, max_depth=1, n_estimators=250..............\n",
      "[CV 4/5; 3/72] END criterion=gini, max_depth=1, n_estimators=250;, score=0.603 total time=   0.1s\n",
      "[CV 5/5; 3/72] START criterion=gini, max_depth=1, n_estimators=250..............\n",
      "[CV 5/5; 3/72] END criterion=gini, max_depth=1, n_estimators=250;, score=0.598 total time=   0.1s\n",
      "[CV 1/5; 4/72] START criterion=gini, max_depth=1, n_estimators=300..............\n",
      "[CV 1/5; 4/72] END criterion=gini, max_depth=1, n_estimators=300;, score=0.610 total time=   0.2s\n",
      "[CV 2/5; 4/72] START criterion=gini, max_depth=1, n_estimators=300..............\n",
      "[CV 2/5; 4/72] END criterion=gini, max_depth=1, n_estimators=300;, score=0.578 total time=   0.2s\n",
      "[CV 3/5; 4/72] START criterion=gini, max_depth=1, n_estimators=300..............\n",
      "[CV 3/5; 4/72] END criterion=gini, max_depth=1, n_estimators=300;, score=0.595 total time=   0.2s\n",
      "[CV 4/5; 4/72] START criterion=gini, max_depth=1, n_estimators=300..............\n",
      "[CV 4/5; 4/72] END criterion=gini, max_depth=1, n_estimators=300;, score=0.593 total time=   0.1s\n",
      "[CV 5/5; 4/72] START criterion=gini, max_depth=1, n_estimators=300..............\n",
      "[CV 5/5; 4/72] END criterion=gini, max_depth=1, n_estimators=300;, score=0.585 total time=   0.2s\n",
      "[CV 1/5; 5/72] START criterion=gini, max_depth=1, n_estimators=400..............\n",
      "[CV 1/5; 5/72] END criterion=gini, max_depth=1, n_estimators=400;, score=0.585 total time=   0.2s\n",
      "[CV 2/5; 5/72] START criterion=gini, max_depth=1, n_estimators=400..............\n",
      "[CV 2/5; 5/72] END criterion=gini, max_depth=1, n_estimators=400;, score=0.595 total time=   0.2s\n",
      "[CV 3/5; 5/72] START criterion=gini, max_depth=1, n_estimators=400..............\n",
      "[CV 3/5; 5/72] END criterion=gini, max_depth=1, n_estimators=400;, score=0.625 total time=   0.2s\n",
      "[CV 4/5; 5/72] START criterion=gini, max_depth=1, n_estimators=400..............\n",
      "[CV 4/5; 5/72] END criterion=gini, max_depth=1, n_estimators=400;, score=0.600 total time=   0.2s\n",
      "[CV 5/5; 5/72] START criterion=gini, max_depth=1, n_estimators=400..............\n",
      "[CV 5/5; 5/72] END criterion=gini, max_depth=1, n_estimators=400;, score=0.570 total time=   0.2s\n",
      "[CV 1/5; 6/72] START criterion=gini, max_depth=1, n_estimators=500..............\n",
      "[CV 1/5; 6/72] END criterion=gini, max_depth=1, n_estimators=500;, score=0.600 total time=   0.2s\n",
      "[CV 2/5; 6/72] START criterion=gini, max_depth=1, n_estimators=500..............\n",
      "[CV 2/5; 6/72] END criterion=gini, max_depth=1, n_estimators=500;, score=0.568 total time=   0.2s\n",
      "[CV 3/5; 6/72] START criterion=gini, max_depth=1, n_estimators=500..............\n",
      "[CV 3/5; 6/72] END criterion=gini, max_depth=1, n_estimators=500;, score=0.575 total time=   0.2s\n",
      "[CV 4/5; 6/72] START criterion=gini, max_depth=1, n_estimators=500..............\n",
      "[CV 4/5; 6/72] END criterion=gini, max_depth=1, n_estimators=500;, score=0.600 total time=   0.2s\n",
      "[CV 5/5; 6/72] START criterion=gini, max_depth=1, n_estimators=500..............\n",
      "[CV 5/5; 6/72] END criterion=gini, max_depth=1, n_estimators=500;, score=0.578 total time=   0.2s\n",
      "[CV 1/5; 7/72] START criterion=gini, max_depth=2, n_estimators=100..............\n",
      "[CV 1/5; 7/72] END criterion=gini, max_depth=2, n_estimators=100;, score=0.762 total time=   0.0s\n",
      "[CV 2/5; 7/72] START criterion=gini, max_depth=2, n_estimators=100..............\n",
      "[CV 2/5; 7/72] END criterion=gini, max_depth=2, n_estimators=100;, score=0.698 total time=   0.0s\n",
      "[CV 3/5; 7/72] START criterion=gini, max_depth=2, n_estimators=100..............\n",
      "[CV 3/5; 7/72] END criterion=gini, max_depth=2, n_estimators=100;, score=0.785 total time=   0.0s\n",
      "[CV 4/5; 7/72] START criterion=gini, max_depth=2, n_estimators=100..............\n",
      "[CV 4/5; 7/72] END criterion=gini, max_depth=2, n_estimators=100;, score=0.762 total time=   0.0s\n",
      "[CV 5/5; 7/72] START criterion=gini, max_depth=2, n_estimators=100..............\n",
      "[CV 5/5; 7/72] END criterion=gini, max_depth=2, n_estimators=100;, score=0.748 total time=   0.0s\n",
      "[CV 1/5; 8/72] START criterion=gini, max_depth=2, n_estimators=200..............\n",
      "[CV 1/5; 8/72] END criterion=gini, max_depth=2, n_estimators=200;, score=0.762 total time=   0.1s\n",
      "[CV 2/5; 8/72] START criterion=gini, max_depth=2, n_estimators=200..............\n",
      "[CV 2/5; 8/72] END criterion=gini, max_depth=2, n_estimators=200;, score=0.730 total time=   0.1s\n",
      "[CV 3/5; 8/72] START criterion=gini, max_depth=2, n_estimators=200..............\n",
      "[CV 3/5; 8/72] END criterion=gini, max_depth=2, n_estimators=200;, score=0.750 total time=   0.1s\n",
      "[CV 4/5; 8/72] START criterion=gini, max_depth=2, n_estimators=200..............\n",
      "[CV 4/5; 8/72] END criterion=gini, max_depth=2, n_estimators=200;, score=0.782 total time=   0.1s\n",
      "[CV 5/5; 8/72] START criterion=gini, max_depth=2, n_estimators=200..............\n",
      "[CV 5/5; 8/72] END criterion=gini, max_depth=2, n_estimators=200;, score=0.755 total time=   0.1s\n",
      "[CV 1/5; 9/72] START criterion=gini, max_depth=2, n_estimators=250..............\n",
      "[CV 1/5; 9/72] END criterion=gini, max_depth=2, n_estimators=250;, score=0.720 total time=   0.1s\n",
      "[CV 2/5; 9/72] START criterion=gini, max_depth=2, n_estimators=250..............\n",
      "[CV 2/5; 9/72] END criterion=gini, max_depth=2, n_estimators=250;, score=0.735 total time=   0.2s\n",
      "[CV 3/5; 9/72] START criterion=gini, max_depth=2, n_estimators=250..............\n",
      "[CV 3/5; 9/72] END criterion=gini, max_depth=2, n_estimators=250;, score=0.777 total time=   0.1s\n",
      "[CV 4/5; 9/72] START criterion=gini, max_depth=2, n_estimators=250..............\n",
      "[CV 4/5; 9/72] END criterion=gini, max_depth=2, n_estimators=250;, score=0.765 total time=   0.1s\n",
      "[CV 5/5; 9/72] START criterion=gini, max_depth=2, n_estimators=250..............\n",
      "[CV 5/5; 9/72] END criterion=gini, max_depth=2, n_estimators=250;, score=0.733 total time=   0.1s\n",
      "[CV 1/5; 10/72] START criterion=gini, max_depth=2, n_estimators=300.............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 10/72] END criterion=gini, max_depth=2, n_estimators=300;, score=0.775 total time=   0.2s\n",
      "[CV 2/5; 10/72] START criterion=gini, max_depth=2, n_estimators=300.............\n",
      "[CV 2/5; 10/72] END criterion=gini, max_depth=2, n_estimators=300;, score=0.755 total time=   0.2s\n",
      "[CV 3/5; 10/72] START criterion=gini, max_depth=2, n_estimators=300.............\n",
      "[CV 3/5; 10/72] END criterion=gini, max_depth=2, n_estimators=300;, score=0.795 total time=   0.2s\n",
      "[CV 4/5; 10/72] START criterion=gini, max_depth=2, n_estimators=300.............\n",
      "[CV 4/5; 10/72] END criterion=gini, max_depth=2, n_estimators=300;, score=0.772 total time=   0.2s\n",
      "[CV 5/5; 10/72] START criterion=gini, max_depth=2, n_estimators=300.............\n",
      "[CV 5/5; 10/72] END criterion=gini, max_depth=2, n_estimators=300;, score=0.740 total time=   0.2s\n",
      "[CV 1/5; 11/72] START criterion=gini, max_depth=2, n_estimators=400.............\n",
      "[CV 1/5; 11/72] END criterion=gini, max_depth=2, n_estimators=400;, score=0.780 total time=   0.2s\n",
      "[CV 2/5; 11/72] START criterion=gini, max_depth=2, n_estimators=400.............\n",
      "[CV 2/5; 11/72] END criterion=gini, max_depth=2, n_estimators=400;, score=0.730 total time=   0.2s\n",
      "[CV 3/5; 11/72] START criterion=gini, max_depth=2, n_estimators=400.............\n",
      "[CV 3/5; 11/72] END criterion=gini, max_depth=2, n_estimators=400;, score=0.805 total time=   0.2s\n",
      "[CV 4/5; 11/72] START criterion=gini, max_depth=2, n_estimators=400.............\n",
      "[CV 4/5; 11/72] END criterion=gini, max_depth=2, n_estimators=400;, score=0.777 total time=   0.2s\n",
      "[CV 5/5; 11/72] START criterion=gini, max_depth=2, n_estimators=400.............\n",
      "[CV 5/5; 11/72] END criterion=gini, max_depth=2, n_estimators=400;, score=0.767 total time=   0.2s\n",
      "[CV 1/5; 12/72] START criterion=gini, max_depth=2, n_estimators=500.............\n",
      "[CV 1/5; 12/72] END criterion=gini, max_depth=2, n_estimators=500;, score=0.738 total time=   0.2s\n",
      "[CV 2/5; 12/72] START criterion=gini, max_depth=2, n_estimators=500.............\n",
      "[CV 2/5; 12/72] END criterion=gini, max_depth=2, n_estimators=500;, score=0.760 total time=   0.2s\n",
      "[CV 3/5; 12/72] START criterion=gini, max_depth=2, n_estimators=500.............\n",
      "[CV 3/5; 12/72] END criterion=gini, max_depth=2, n_estimators=500;, score=0.770 total time=   0.2s\n",
      "[CV 4/5; 12/72] START criterion=gini, max_depth=2, n_estimators=500.............\n",
      "[CV 4/5; 12/72] END criterion=gini, max_depth=2, n_estimators=500;, score=0.767 total time=   0.3s\n",
      "[CV 5/5; 12/72] START criterion=gini, max_depth=2, n_estimators=500.............\n",
      "[CV 5/5; 12/72] END criterion=gini, max_depth=2, n_estimators=500;, score=0.733 total time=   0.2s\n",
      "[CV 1/5; 13/72] START criterion=gini, max_depth=5, n_estimators=100.............\n",
      "[CV 1/5; 13/72] END criterion=gini, max_depth=5, n_estimators=100;, score=0.805 total time=   0.0s\n",
      "[CV 2/5; 13/72] START criterion=gini, max_depth=5, n_estimators=100.............\n",
      "[CV 2/5; 13/72] END criterion=gini, max_depth=5, n_estimators=100;, score=0.848 total time=   0.0s\n",
      "[CV 3/5; 13/72] START criterion=gini, max_depth=5, n_estimators=100.............\n",
      "[CV 3/5; 13/72] END criterion=gini, max_depth=5, n_estimators=100;, score=0.873 total time=   0.0s\n",
      "[CV 4/5; 13/72] START criterion=gini, max_depth=5, n_estimators=100.............\n",
      "[CV 4/5; 13/72] END criterion=gini, max_depth=5, n_estimators=100;, score=0.828 total time=   0.0s\n",
      "[CV 5/5; 13/72] START criterion=gini, max_depth=5, n_estimators=100.............\n",
      "[CV 5/5; 13/72] END criterion=gini, max_depth=5, n_estimators=100;, score=0.848 total time=   0.0s\n",
      "[CV 1/5; 14/72] START criterion=gini, max_depth=5, n_estimators=200.............\n",
      "[CV 1/5; 14/72] END criterion=gini, max_depth=5, n_estimators=200;, score=0.830 total time=   0.1s\n",
      "[CV 2/5; 14/72] START criterion=gini, max_depth=5, n_estimators=200.............\n",
      "[CV 2/5; 14/72] END criterion=gini, max_depth=5, n_estimators=200;, score=0.843 total time=   0.1s\n",
      "[CV 3/5; 14/72] START criterion=gini, max_depth=5, n_estimators=200.............\n",
      "[CV 3/5; 14/72] END criterion=gini, max_depth=5, n_estimators=200;, score=0.875 total time=   0.1s\n",
      "[CV 4/5; 14/72] START criterion=gini, max_depth=5, n_estimators=200.............\n",
      "[CV 4/5; 14/72] END criterion=gini, max_depth=5, n_estimators=200;, score=0.845 total time=   0.2s\n",
      "[CV 5/5; 14/72] START criterion=gini, max_depth=5, n_estimators=200.............\n",
      "[CV 5/5; 14/72] END criterion=gini, max_depth=5, n_estimators=200;, score=0.825 total time=   0.1s\n",
      "[CV 1/5; 15/72] START criterion=gini, max_depth=5, n_estimators=250.............\n",
      "[CV 1/5; 15/72] END criterion=gini, max_depth=5, n_estimators=250;, score=0.838 total time=   0.2s\n",
      "[CV 2/5; 15/72] START criterion=gini, max_depth=5, n_estimators=250.............\n",
      "[CV 2/5; 15/72] END criterion=gini, max_depth=5, n_estimators=250;, score=0.840 total time=   0.1s\n",
      "[CV 3/5; 15/72] START criterion=gini, max_depth=5, n_estimators=250.............\n",
      "[CV 3/5; 15/72] END criterion=gini, max_depth=5, n_estimators=250;, score=0.853 total time=   0.1s\n",
      "[CV 4/5; 15/72] START criterion=gini, max_depth=5, n_estimators=250.............\n",
      "[CV 4/5; 15/72] END criterion=gini, max_depth=5, n_estimators=250;, score=0.828 total time=   0.1s\n",
      "[CV 5/5; 15/72] START criterion=gini, max_depth=5, n_estimators=250.............\n",
      "[CV 5/5; 15/72] END criterion=gini, max_depth=5, n_estimators=250;, score=0.818 total time=   0.1s\n",
      "[CV 1/5; 16/72] START criterion=gini, max_depth=5, n_estimators=300.............\n",
      "[CV 1/5; 16/72] END criterion=gini, max_depth=5, n_estimators=300;, score=0.835 total time=   0.2s\n",
      "[CV 2/5; 16/72] START criterion=gini, max_depth=5, n_estimators=300.............\n",
      "[CV 2/5; 16/72] END criterion=gini, max_depth=5, n_estimators=300;, score=0.843 total time=   0.2s\n",
      "[CV 3/5; 16/72] START criterion=gini, max_depth=5, n_estimators=300.............\n",
      "[CV 3/5; 16/72] END criterion=gini, max_depth=5, n_estimators=300;, score=0.865 total time=   0.2s\n",
      "[CV 4/5; 16/72] START criterion=gini, max_depth=5, n_estimators=300.............\n",
      "[CV 4/5; 16/72] END criterion=gini, max_depth=5, n_estimators=300;, score=0.835 total time=   0.2s\n",
      "[CV 5/5; 16/72] START criterion=gini, max_depth=5, n_estimators=300.............\n",
      "[CV 5/5; 16/72] END criterion=gini, max_depth=5, n_estimators=300;, score=0.818 total time=   0.2s\n",
      "[CV 1/5; 17/72] START criterion=gini, max_depth=5, n_estimators=400.............\n",
      "[CV 1/5; 17/72] END criterion=gini, max_depth=5, n_estimators=400;, score=0.828 total time=   0.2s\n",
      "[CV 2/5; 17/72] START criterion=gini, max_depth=5, n_estimators=400.............\n",
      "[CV 2/5; 17/72] END criterion=gini, max_depth=5, n_estimators=400;, score=0.843 total time=   0.2s\n",
      "[CV 3/5; 17/72] START criterion=gini, max_depth=5, n_estimators=400.............\n",
      "[CV 3/5; 17/72] END criterion=gini, max_depth=5, n_estimators=400;, score=0.863 total time=   0.2s\n",
      "[CV 4/5; 17/72] START criterion=gini, max_depth=5, n_estimators=400.............\n",
      "[CV 4/5; 17/72] END criterion=gini, max_depth=5, n_estimators=400;, score=0.840 total time=   0.2s\n",
      "[CV 5/5; 17/72] START criterion=gini, max_depth=5, n_estimators=400.............\n",
      "[CV 5/5; 17/72] END criterion=gini, max_depth=5, n_estimators=400;, score=0.820 total time=   0.2s\n",
      "[CV 1/5; 18/72] START criterion=gini, max_depth=5, n_estimators=500.............\n",
      "[CV 1/5; 18/72] END criterion=gini, max_depth=5, n_estimators=500;, score=0.840 total time=   0.3s\n",
      "[CV 2/5; 18/72] START criterion=gini, max_depth=5, n_estimators=500.............\n",
      "[CV 2/5; 18/72] END criterion=gini, max_depth=5, n_estimators=500;, score=0.843 total time=   0.2s\n",
      "[CV 3/5; 18/72] START criterion=gini, max_depth=5, n_estimators=500.............\n",
      "[CV 3/5; 18/72] END criterion=gini, max_depth=5, n_estimators=500;, score=0.870 total time=   0.3s\n",
      "[CV 4/5; 18/72] START criterion=gini, max_depth=5, n_estimators=500.............\n",
      "[CV 4/5; 18/72] END criterion=gini, max_depth=5, n_estimators=500;, score=0.835 total time=   0.2s\n",
      "[CV 5/5; 18/72] START criterion=gini, max_depth=5, n_estimators=500.............\n",
      "[CV 5/5; 18/72] END criterion=gini, max_depth=5, n_estimators=500;, score=0.823 total time=   0.3s\n",
      "[CV 1/5; 19/72] START criterion=gini, max_depth=7, n_estimators=100.............\n",
      "[CV 1/5; 19/72] END criterion=gini, max_depth=7, n_estimators=100;, score=0.863 total time=   0.0s\n",
      "[CV 2/5; 19/72] START criterion=gini, max_depth=7, n_estimators=100.............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 19/72] END criterion=gini, max_depth=7, n_estimators=100;, score=0.853 total time=   0.0s\n",
      "[CV 3/5; 19/72] START criterion=gini, max_depth=7, n_estimators=100.............\n",
      "[CV 3/5; 19/72] END criterion=gini, max_depth=7, n_estimators=100;, score=0.885 total time=   0.0s\n",
      "[CV 4/5; 19/72] START criterion=gini, max_depth=7, n_estimators=100.............\n",
      "[CV 4/5; 19/72] END criterion=gini, max_depth=7, n_estimators=100;, score=0.868 total time=   0.0s\n",
      "[CV 5/5; 19/72] START criterion=gini, max_depth=7, n_estimators=100.............\n",
      "[CV 5/5; 19/72] END criterion=gini, max_depth=7, n_estimators=100;, score=0.843 total time=   0.0s\n",
      "[CV 1/5; 20/72] START criterion=gini, max_depth=7, n_estimators=200.............\n",
      "[CV 1/5; 20/72] END criterion=gini, max_depth=7, n_estimators=200;, score=0.853 total time=   0.1s\n",
      "[CV 2/5; 20/72] START criterion=gini, max_depth=7, n_estimators=200.............\n",
      "[CV 2/5; 20/72] END criterion=gini, max_depth=7, n_estimators=200;, score=0.868 total time=   0.2s\n",
      "[CV 3/5; 20/72] START criterion=gini, max_depth=7, n_estimators=200.............\n",
      "[CV 3/5; 20/72] END criterion=gini, max_depth=7, n_estimators=200;, score=0.885 total time=   0.1s\n",
      "[CV 4/5; 20/72] START criterion=gini, max_depth=7, n_estimators=200.............\n",
      "[CV 4/5; 20/72] END criterion=gini, max_depth=7, n_estimators=200;, score=0.853 total time=   0.1s\n",
      "[CV 5/5; 20/72] START criterion=gini, max_depth=7, n_estimators=200.............\n",
      "[CV 5/5; 20/72] END criterion=gini, max_depth=7, n_estimators=200;, score=0.830 total time=   0.1s\n",
      "[CV 1/5; 21/72] START criterion=gini, max_depth=7, n_estimators=250.............\n",
      "[CV 1/5; 21/72] END criterion=gini, max_depth=7, n_estimators=250;, score=0.860 total time=   0.1s\n",
      "[CV 2/5; 21/72] START criterion=gini, max_depth=7, n_estimators=250.............\n",
      "[CV 2/5; 21/72] END criterion=gini, max_depth=7, n_estimators=250;, score=0.877 total time=   0.1s\n",
      "[CV 3/5; 21/72] START criterion=gini, max_depth=7, n_estimators=250.............\n",
      "[CV 3/5; 21/72] END criterion=gini, max_depth=7, n_estimators=250;, score=0.897 total time=   0.1s\n",
      "[CV 4/5; 21/72] START criterion=gini, max_depth=7, n_estimators=250.............\n",
      "[CV 4/5; 21/72] END criterion=gini, max_depth=7, n_estimators=250;, score=0.855 total time=   0.1s\n",
      "[CV 5/5; 21/72] START criterion=gini, max_depth=7, n_estimators=250.............\n",
      "[CV 5/5; 21/72] END criterion=gini, max_depth=7, n_estimators=250;, score=0.843 total time=   0.1s\n",
      "[CV 1/5; 22/72] START criterion=gini, max_depth=7, n_estimators=300.............\n",
      "[CV 1/5; 22/72] END criterion=gini, max_depth=7, n_estimators=300;, score=0.865 total time=   0.2s\n",
      "[CV 2/5; 22/72] START criterion=gini, max_depth=7, n_estimators=300.............\n",
      "[CV 2/5; 22/72] END criterion=gini, max_depth=7, n_estimators=300;, score=0.868 total time=   0.2s\n",
      "[CV 3/5; 22/72] START criterion=gini, max_depth=7, n_estimators=300.............\n",
      "[CV 3/5; 22/72] END criterion=gini, max_depth=7, n_estimators=300;, score=0.885 total time=   0.2s\n",
      "[CV 4/5; 22/72] START criterion=gini, max_depth=7, n_estimators=300.............\n",
      "[CV 4/5; 22/72] END criterion=gini, max_depth=7, n_estimators=300;, score=0.855 total time=   0.2s\n",
      "[CV 5/5; 22/72] START criterion=gini, max_depth=7, n_estimators=300.............\n",
      "[CV 5/5; 22/72] END criterion=gini, max_depth=7, n_estimators=300;, score=0.848 total time=   0.2s\n",
      "[CV 1/5; 23/72] START criterion=gini, max_depth=7, n_estimators=400.............\n",
      "[CV 1/5; 23/72] END criterion=gini, max_depth=7, n_estimators=400;, score=0.858 total time=   0.3s\n",
      "[CV 2/5; 23/72] START criterion=gini, max_depth=7, n_estimators=400.............\n",
      "[CV 2/5; 23/72] END criterion=gini, max_depth=7, n_estimators=400;, score=0.877 total time=   0.2s\n",
      "[CV 3/5; 23/72] START criterion=gini, max_depth=7, n_estimators=400.............\n",
      "[CV 3/5; 23/72] END criterion=gini, max_depth=7, n_estimators=400;, score=0.890 total time=   0.2s\n",
      "[CV 4/5; 23/72] START criterion=gini, max_depth=7, n_estimators=400.............\n",
      "[CV 4/5; 23/72] END criterion=gini, max_depth=7, n_estimators=400;, score=0.868 total time=   0.2s\n",
      "[CV 5/5; 23/72] START criterion=gini, max_depth=7, n_estimators=400.............\n",
      "[CV 5/5; 23/72] END criterion=gini, max_depth=7, n_estimators=400;, score=0.845 total time=   0.2s\n",
      "[CV 1/5; 24/72] START criterion=gini, max_depth=7, n_estimators=500.............\n",
      "[CV 1/5; 24/72] END criterion=gini, max_depth=7, n_estimators=500;, score=0.863 total time=   0.3s\n",
      "[CV 2/5; 24/72] START criterion=gini, max_depth=7, n_estimators=500.............\n",
      "[CV 2/5; 24/72] END criterion=gini, max_depth=7, n_estimators=500;, score=0.850 total time=   0.3s\n",
      "[CV 3/5; 24/72] START criterion=gini, max_depth=7, n_estimators=500.............\n",
      "[CV 3/5; 24/72] END criterion=gini, max_depth=7, n_estimators=500;, score=0.882 total time=   0.3s\n",
      "[CV 4/5; 24/72] START criterion=gini, max_depth=7, n_estimators=500.............\n",
      "[CV 4/5; 24/72] END criterion=gini, max_depth=7, n_estimators=500;, score=0.863 total time=   0.3s\n",
      "[CV 5/5; 24/72] START criterion=gini, max_depth=7, n_estimators=500.............\n",
      "[CV 5/5; 24/72] END criterion=gini, max_depth=7, n_estimators=500;, score=0.838 total time=   0.3s\n",
      "[CV 1/5; 25/72] START criterion=gini, max_depth=11, n_estimators=100............\n",
      "[CV 1/5; 25/72] END criterion=gini, max_depth=11, n_estimators=100;, score=0.863 total time=   0.0s\n",
      "[CV 2/5; 25/72] START criterion=gini, max_depth=11, n_estimators=100............\n",
      "[CV 2/5; 25/72] END criterion=gini, max_depth=11, n_estimators=100;, score=0.873 total time=   0.0s\n",
      "[CV 3/5; 25/72] START criterion=gini, max_depth=11, n_estimators=100............\n",
      "[CV 3/5; 25/72] END criterion=gini, max_depth=11, n_estimators=100;, score=0.890 total time=   0.0s\n",
      "[CV 4/5; 25/72] START criterion=gini, max_depth=11, n_estimators=100............\n",
      "[CV 4/5; 25/72] END criterion=gini, max_depth=11, n_estimators=100;, score=0.882 total time=   0.0s\n",
      "[CV 5/5; 25/72] START criterion=gini, max_depth=11, n_estimators=100............\n",
      "[CV 5/5; 25/72] END criterion=gini, max_depth=11, n_estimators=100;, score=0.845 total time=   0.0s\n",
      "[CV 1/5; 26/72] START criterion=gini, max_depth=11, n_estimators=200............\n",
      "[CV 1/5; 26/72] END criterion=gini, max_depth=11, n_estimators=200;, score=0.890 total time=   0.1s\n",
      "[CV 2/5; 26/72] START criterion=gini, max_depth=11, n_estimators=200............\n",
      "[CV 2/5; 26/72] END criterion=gini, max_depth=11, n_estimators=200;, score=0.870 total time=   0.1s\n",
      "[CV 3/5; 26/72] START criterion=gini, max_depth=11, n_estimators=200............\n",
      "[CV 3/5; 26/72] END criterion=gini, max_depth=11, n_estimators=200;, score=0.887 total time=   0.1s\n",
      "[CV 4/5; 26/72] START criterion=gini, max_depth=11, n_estimators=200............\n",
      "[CV 4/5; 26/72] END criterion=gini, max_depth=11, n_estimators=200;, score=0.875 total time=   0.1s\n",
      "[CV 5/5; 26/72] START criterion=gini, max_depth=11, n_estimators=200............\n",
      "[CV 5/5; 26/72] END criterion=gini, max_depth=11, n_estimators=200;, score=0.858 total time=   0.1s\n",
      "[CV 1/5; 27/72] START criterion=gini, max_depth=11, n_estimators=250............\n",
      "[CV 1/5; 27/72] END criterion=gini, max_depth=11, n_estimators=250;, score=0.877 total time=   0.1s\n",
      "[CV 2/5; 27/72] START criterion=gini, max_depth=11, n_estimators=250............\n",
      "[CV 2/5; 27/72] END criterion=gini, max_depth=11, n_estimators=250;, score=0.887 total time=   0.1s\n",
      "[CV 3/5; 27/72] START criterion=gini, max_depth=11, n_estimators=250............\n",
      "[CV 3/5; 27/72] END criterion=gini, max_depth=11, n_estimators=250;, score=0.890 total time=   0.1s\n",
      "[CV 4/5; 27/72] START criterion=gini, max_depth=11, n_estimators=250............\n",
      "[CV 4/5; 27/72] END criterion=gini, max_depth=11, n_estimators=250;, score=0.877 total time=   0.1s\n",
      "[CV 5/5; 27/72] START criterion=gini, max_depth=11, n_estimators=250............\n",
      "[CV 5/5; 27/72] END criterion=gini, max_depth=11, n_estimators=250;, score=0.848 total time=   0.1s\n",
      "[CV 1/5; 28/72] START criterion=gini, max_depth=11, n_estimators=300............\n",
      "[CV 1/5; 28/72] END criterion=gini, max_depth=11, n_estimators=300;, score=0.880 total time=   0.2s\n",
      "[CV 2/5; 28/72] START criterion=gini, max_depth=11, n_estimators=300............\n",
      "[CV 2/5; 28/72] END criterion=gini, max_depth=11, n_estimators=300;, score=0.890 total time=   0.2s\n",
      "[CV 3/5; 28/72] START criterion=gini, max_depth=11, n_estimators=300............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 28/72] END criterion=gini, max_depth=11, n_estimators=300;, score=0.885 total time=   0.2s\n",
      "[CV 4/5; 28/72] START criterion=gini, max_depth=11, n_estimators=300............\n",
      "[CV 4/5; 28/72] END criterion=gini, max_depth=11, n_estimators=300;, score=0.880 total time=   0.2s\n",
      "[CV 5/5; 28/72] START criterion=gini, max_depth=11, n_estimators=300............\n",
      "[CV 5/5; 28/72] END criterion=gini, max_depth=11, n_estimators=300;, score=0.873 total time=   0.2s\n",
      "[CV 1/5; 29/72] START criterion=gini, max_depth=11, n_estimators=400............\n",
      "[CV 1/5; 29/72] END criterion=gini, max_depth=11, n_estimators=400;, score=0.890 total time=   0.3s\n",
      "[CV 2/5; 29/72] START criterion=gini, max_depth=11, n_estimators=400............\n",
      "[CV 2/5; 29/72] END criterion=gini, max_depth=11, n_estimators=400;, score=0.892 total time=   0.2s\n",
      "[CV 3/5; 29/72] START criterion=gini, max_depth=11, n_estimators=400............\n",
      "[CV 3/5; 29/72] END criterion=gini, max_depth=11, n_estimators=400;, score=0.890 total time=   0.3s\n",
      "[CV 4/5; 29/72] START criterion=gini, max_depth=11, n_estimators=400............\n",
      "[CV 4/5; 29/72] END criterion=gini, max_depth=11, n_estimators=400;, score=0.865 total time=   0.3s\n",
      "[CV 5/5; 29/72] START criterion=gini, max_depth=11, n_estimators=400............\n",
      "[CV 5/5; 29/72] END criterion=gini, max_depth=11, n_estimators=400;, score=0.873 total time=   0.2s\n",
      "[CV 1/5; 30/72] START criterion=gini, max_depth=11, n_estimators=500............\n",
      "[CV 1/5; 30/72] END criterion=gini, max_depth=11, n_estimators=500;, score=0.875 total time=   0.3s\n",
      "[CV 2/5; 30/72] START criterion=gini, max_depth=11, n_estimators=500............\n",
      "[CV 2/5; 30/72] END criterion=gini, max_depth=11, n_estimators=500;, score=0.882 total time=   0.3s\n",
      "[CV 3/5; 30/72] START criterion=gini, max_depth=11, n_estimators=500............\n",
      "[CV 3/5; 30/72] END criterion=gini, max_depth=11, n_estimators=500;, score=0.895 total time=   0.3s\n",
      "[CV 4/5; 30/72] START criterion=gini, max_depth=11, n_estimators=500............\n",
      "[CV 4/5; 30/72] END criterion=gini, max_depth=11, n_estimators=500;, score=0.868 total time=   0.4s\n",
      "[CV 5/5; 30/72] START criterion=gini, max_depth=11, n_estimators=500............\n",
      "[CV 5/5; 30/72] END criterion=gini, max_depth=11, n_estimators=500;, score=0.870 total time=   0.3s\n",
      "[CV 1/5; 31/72] START criterion=gini, max_depth=15, n_estimators=100............\n",
      "[CV 1/5; 31/72] END criterion=gini, max_depth=15, n_estimators=100;, score=0.870 total time=   0.0s\n",
      "[CV 2/5; 31/72] START criterion=gini, max_depth=15, n_estimators=100............\n",
      "[CV 2/5; 31/72] END criterion=gini, max_depth=15, n_estimators=100;, score=0.875 total time=   0.0s\n",
      "[CV 3/5; 31/72] START criterion=gini, max_depth=15, n_estimators=100............\n",
      "[CV 3/5; 31/72] END criterion=gini, max_depth=15, n_estimators=100;, score=0.905 total time=   0.0s\n",
      "[CV 4/5; 31/72] START criterion=gini, max_depth=15, n_estimators=100............\n",
      "[CV 4/5; 31/72] END criterion=gini, max_depth=15, n_estimators=100;, score=0.860 total time=   0.0s\n",
      "[CV 5/5; 31/72] START criterion=gini, max_depth=15, n_estimators=100............\n",
      "[CV 5/5; 31/72] END criterion=gini, max_depth=15, n_estimators=100;, score=0.858 total time=   0.0s\n",
      "[CV 1/5; 32/72] START criterion=gini, max_depth=15, n_estimators=200............\n",
      "[CV 1/5; 32/72] END criterion=gini, max_depth=15, n_estimators=200;, score=0.887 total time=   0.1s\n",
      "[CV 2/5; 32/72] START criterion=gini, max_depth=15, n_estimators=200............\n",
      "[CV 2/5; 32/72] END criterion=gini, max_depth=15, n_estimators=200;, score=0.885 total time=   0.1s\n",
      "[CV 3/5; 32/72] START criterion=gini, max_depth=15, n_estimators=200............\n",
      "[CV 3/5; 32/72] END criterion=gini, max_depth=15, n_estimators=200;, score=0.890 total time=   0.1s\n",
      "[CV 4/5; 32/72] START criterion=gini, max_depth=15, n_estimators=200............\n",
      "[CV 4/5; 32/72] END criterion=gini, max_depth=15, n_estimators=200;, score=0.870 total time=   0.1s\n",
      "[CV 5/5; 32/72] START criterion=gini, max_depth=15, n_estimators=200............\n",
      "[CV 5/5; 32/72] END criterion=gini, max_depth=15, n_estimators=200;, score=0.865 total time=   0.1s\n",
      "[CV 1/5; 33/72] START criterion=gini, max_depth=15, n_estimators=250............\n",
      "[CV 1/5; 33/72] END criterion=gini, max_depth=15, n_estimators=250;, score=0.890 total time=   0.1s\n",
      "[CV 2/5; 33/72] START criterion=gini, max_depth=15, n_estimators=250............\n",
      "[CV 2/5; 33/72] END criterion=gini, max_depth=15, n_estimators=250;, score=0.880 total time=   0.1s\n",
      "[CV 3/5; 33/72] START criterion=gini, max_depth=15, n_estimators=250............\n",
      "[CV 3/5; 33/72] END criterion=gini, max_depth=15, n_estimators=250;, score=0.892 total time=   0.1s\n",
      "[CV 4/5; 33/72] START criterion=gini, max_depth=15, n_estimators=250............\n",
      "[CV 4/5; 33/72] END criterion=gini, max_depth=15, n_estimators=250;, score=0.875 total time=   0.1s\n",
      "[CV 5/5; 33/72] START criterion=gini, max_depth=15, n_estimators=250............\n",
      "[CV 5/5; 33/72] END criterion=gini, max_depth=15, n_estimators=250;, score=0.870 total time=   0.1s\n",
      "[CV 1/5; 34/72] START criterion=gini, max_depth=15, n_estimators=300............\n",
      "[CV 1/5; 34/72] END criterion=gini, max_depth=15, n_estimators=300;, score=0.887 total time=   0.2s\n",
      "[CV 2/5; 34/72] START criterion=gini, max_depth=15, n_estimators=300............\n",
      "[CV 2/5; 34/72] END criterion=gini, max_depth=15, n_estimators=300;, score=0.890 total time=   0.2s\n",
      "[CV 3/5; 34/72] START criterion=gini, max_depth=15, n_estimators=300............\n",
      "[CV 3/5; 34/72] END criterion=gini, max_depth=15, n_estimators=300;, score=0.895 total time=   0.2s\n",
      "[CV 4/5; 34/72] START criterion=gini, max_depth=15, n_estimators=300............\n",
      "[CV 4/5; 34/72] END criterion=gini, max_depth=15, n_estimators=300;, score=0.860 total time=   0.2s\n",
      "[CV 5/5; 34/72] START criterion=gini, max_depth=15, n_estimators=300............\n",
      "[CV 5/5; 34/72] END criterion=gini, max_depth=15, n_estimators=300;, score=0.865 total time=   0.2s\n",
      "[CV 1/5; 35/72] START criterion=gini, max_depth=15, n_estimators=400............\n",
      "[CV 1/5; 35/72] END criterion=gini, max_depth=15, n_estimators=400;, score=0.885 total time=   0.2s\n",
      "[CV 2/5; 35/72] START criterion=gini, max_depth=15, n_estimators=400............\n",
      "[CV 2/5; 35/72] END criterion=gini, max_depth=15, n_estimators=400;, score=0.885 total time=   0.3s\n",
      "[CV 3/5; 35/72] START criterion=gini, max_depth=15, n_estimators=400............\n",
      "[CV 3/5; 35/72] END criterion=gini, max_depth=15, n_estimators=400;, score=0.897 total time=   0.2s\n",
      "[CV 4/5; 35/72] START criterion=gini, max_depth=15, n_estimators=400............\n",
      "[CV 4/5; 35/72] END criterion=gini, max_depth=15, n_estimators=400;, score=0.885 total time=   0.3s\n",
      "[CV 5/5; 35/72] START criterion=gini, max_depth=15, n_estimators=400............\n",
      "[CV 5/5; 35/72] END criterion=gini, max_depth=15, n_estimators=400;, score=0.858 total time=   0.2s\n",
      "[CV 1/5; 36/72] START criterion=gini, max_depth=15, n_estimators=500............\n",
      "[CV 1/5; 36/72] END criterion=gini, max_depth=15, n_estimators=500;, score=0.875 total time=   0.3s\n",
      "[CV 2/5; 36/72] START criterion=gini, max_depth=15, n_estimators=500............\n",
      "[CV 2/5; 36/72] END criterion=gini, max_depth=15, n_estimators=500;, score=0.887 total time=   0.4s\n",
      "[CV 3/5; 36/72] START criterion=gini, max_depth=15, n_estimators=500............\n",
      "[CV 3/5; 36/72] END criterion=gini, max_depth=15, n_estimators=500;, score=0.900 total time=   0.3s\n",
      "[CV 4/5; 36/72] START criterion=gini, max_depth=15, n_estimators=500............\n",
      "[CV 4/5; 36/72] END criterion=gini, max_depth=15, n_estimators=500;, score=0.868 total time=   0.3s\n",
      "[CV 5/5; 36/72] START criterion=gini, max_depth=15, n_estimators=500............\n",
      "[CV 5/5; 36/72] END criterion=gini, max_depth=15, n_estimators=500;, score=0.868 total time=   0.3s\n",
      "[CV 1/5; 37/72] START criterion=entropy, max_depth=1, n_estimators=100..........\n",
      "[CV 1/5; 37/72] END criterion=entropy, max_depth=1, n_estimators=100;, score=0.562 total time=   0.0s\n",
      "[CV 2/5; 37/72] START criterion=entropy, max_depth=1, n_estimators=100..........\n",
      "[CV 2/5; 37/72] END criterion=entropy, max_depth=1, n_estimators=100;, score=0.573 total time=   0.0s\n",
      "[CV 3/5; 37/72] START criterion=entropy, max_depth=1, n_estimators=100..........\n",
      "[CV 3/5; 37/72] END criterion=entropy, max_depth=1, n_estimators=100;, score=0.562 total time=   0.0s\n",
      "[CV 4/5; 37/72] START criterion=entropy, max_depth=1, n_estimators=100..........\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 37/72] END criterion=entropy, max_depth=1, n_estimators=100;, score=0.555 total time=   0.0s\n",
      "[CV 5/5; 37/72] START criterion=entropy, max_depth=1, n_estimators=100..........\n",
      "[CV 5/5; 37/72] END criterion=entropy, max_depth=1, n_estimators=100;, score=0.555 total time=   0.0s\n",
      "[CV 1/5; 38/72] START criterion=entropy, max_depth=1, n_estimators=200..........\n",
      "[CV 1/5; 38/72] END criterion=entropy, max_depth=1, n_estimators=200;, score=0.568 total time=   0.1s\n",
      "[CV 2/5; 38/72] START criterion=entropy, max_depth=1, n_estimators=200..........\n",
      "[CV 2/5; 38/72] END criterion=entropy, max_depth=1, n_estimators=200;, score=0.545 total time=   0.1s\n",
      "[CV 3/5; 38/72] START criterion=entropy, max_depth=1, n_estimators=200..........\n",
      "[CV 3/5; 38/72] END criterion=entropy, max_depth=1, n_estimators=200;, score=0.555 total time=   0.1s\n",
      "[CV 4/5; 38/72] START criterion=entropy, max_depth=1, n_estimators=200..........\n",
      "[CV 4/5; 38/72] END criterion=entropy, max_depth=1, n_estimators=200;, score=0.570 total time=   0.1s\n",
      "[CV 5/5; 38/72] START criterion=entropy, max_depth=1, n_estimators=200..........\n",
      "[CV 5/5; 38/72] END criterion=entropy, max_depth=1, n_estimators=200;, score=0.537 total time=   0.1s\n",
      "[CV 1/5; 39/72] START criterion=entropy, max_depth=1, n_estimators=250..........\n",
      "[CV 1/5; 39/72] END criterion=entropy, max_depth=1, n_estimators=250;, score=0.573 total time=   0.1s\n",
      "[CV 2/5; 39/72] START criterion=entropy, max_depth=1, n_estimators=250..........\n",
      "[CV 2/5; 39/72] END criterion=entropy, max_depth=1, n_estimators=250;, score=0.547 total time=   0.1s\n",
      "[CV 3/5; 39/72] START criterion=entropy, max_depth=1, n_estimators=250..........\n",
      "[CV 3/5; 39/72] END criterion=entropy, max_depth=1, n_estimators=250;, score=0.537 total time=   0.1s\n",
      "[CV 4/5; 39/72] START criterion=entropy, max_depth=1, n_estimators=250..........\n",
      "[CV 4/5; 39/72] END criterion=entropy, max_depth=1, n_estimators=250;, score=0.578 total time=   0.1s\n",
      "[CV 5/5; 39/72] START criterion=entropy, max_depth=1, n_estimators=250..........\n",
      "[CV 5/5; 39/72] END criterion=entropy, max_depth=1, n_estimators=250;, score=0.565 total time=   0.1s\n",
      "[CV 1/5; 40/72] START criterion=entropy, max_depth=1, n_estimators=300..........\n",
      "[CV 1/5; 40/72] END criterion=entropy, max_depth=1, n_estimators=300;, score=0.595 total time=   0.2s\n",
      "[CV 2/5; 40/72] START criterion=entropy, max_depth=1, n_estimators=300..........\n",
      "[CV 2/5; 40/72] END criterion=entropy, max_depth=1, n_estimators=300;, score=0.542 total time=   0.2s\n",
      "[CV 3/5; 40/72] START criterion=entropy, max_depth=1, n_estimators=300..........\n",
      "[CV 3/5; 40/72] END criterion=entropy, max_depth=1, n_estimators=300;, score=0.552 total time=   0.2s\n",
      "[CV 4/5; 40/72] START criterion=entropy, max_depth=1, n_estimators=300..........\n",
      "[CV 4/5; 40/72] END criterion=entropy, max_depth=1, n_estimators=300;, score=0.557 total time=   0.2s\n",
      "[CV 5/5; 40/72] START criterion=entropy, max_depth=1, n_estimators=300..........\n",
      "[CV 5/5; 40/72] END criterion=entropy, max_depth=1, n_estimators=300;, score=0.550 total time=   0.2s\n",
      "[CV 1/5; 41/72] START criterion=entropy, max_depth=1, n_estimators=400..........\n",
      "[CV 1/5; 41/72] END criterion=entropy, max_depth=1, n_estimators=400;, score=0.545 total time=   0.2s\n",
      "[CV 2/5; 41/72] START criterion=entropy, max_depth=1, n_estimators=400..........\n",
      "[CV 2/5; 41/72] END criterion=entropy, max_depth=1, n_estimators=400;, score=0.550 total time=   0.2s\n",
      "[CV 3/5; 41/72] START criterion=entropy, max_depth=1, n_estimators=400..........\n",
      "[CV 3/5; 41/72] END criterion=entropy, max_depth=1, n_estimators=400;, score=0.557 total time=   0.2s\n",
      "[CV 4/5; 41/72] START criterion=entropy, max_depth=1, n_estimators=400..........\n",
      "[CV 4/5; 41/72] END criterion=entropy, max_depth=1, n_estimators=400;, score=0.542 total time=   0.3s\n",
      "[CV 5/5; 41/72] START criterion=entropy, max_depth=1, n_estimators=400..........\n",
      "[CV 5/5; 41/72] END criterion=entropy, max_depth=1, n_estimators=400;, score=0.552 total time=   0.2s\n",
      "[CV 1/5; 42/72] START criterion=entropy, max_depth=1, n_estimators=500..........\n",
      "[CV 1/5; 42/72] END criterion=entropy, max_depth=1, n_estimators=500;, score=0.575 total time=   0.2s\n",
      "[CV 2/5; 42/72] START criterion=entropy, max_depth=1, n_estimators=500..........\n",
      "[CV 2/5; 42/72] END criterion=entropy, max_depth=1, n_estimators=500;, score=0.565 total time=   0.2s\n",
      "[CV 3/5; 42/72] START criterion=entropy, max_depth=1, n_estimators=500..........\n",
      "[CV 3/5; 42/72] END criterion=entropy, max_depth=1, n_estimators=500;, score=0.557 total time=   0.2s\n",
      "[CV 4/5; 42/72] START criterion=entropy, max_depth=1, n_estimators=500..........\n",
      "[CV 4/5; 42/72] END criterion=entropy, max_depth=1, n_estimators=500;, score=0.557 total time=   0.2s\n",
      "[CV 5/5; 42/72] START criterion=entropy, max_depth=1, n_estimators=500..........\n",
      "[CV 5/5; 42/72] END criterion=entropy, max_depth=1, n_estimators=500;, score=0.555 total time=   0.2s\n",
      "[CV 1/5; 43/72] START criterion=entropy, max_depth=2, n_estimators=100..........\n",
      "[CV 1/5; 43/72] END criterion=entropy, max_depth=2, n_estimators=100;, score=0.723 total time=   0.0s\n",
      "[CV 2/5; 43/72] START criterion=entropy, max_depth=2, n_estimators=100..........\n",
      "[CV 2/5; 43/72] END criterion=entropy, max_depth=2, n_estimators=100;, score=0.705 total time=   0.0s\n",
      "[CV 3/5; 43/72] START criterion=entropy, max_depth=2, n_estimators=100..........\n",
      "[CV 3/5; 43/72] END criterion=entropy, max_depth=2, n_estimators=100;, score=0.693 total time=   0.0s\n",
      "[CV 4/5; 43/72] START criterion=entropy, max_depth=2, n_estimators=100..........\n",
      "[CV 4/5; 43/72] END criterion=entropy, max_depth=2, n_estimators=100;, score=0.715 total time=   0.0s\n",
      "[CV 5/5; 43/72] START criterion=entropy, max_depth=2, n_estimators=100..........\n",
      "[CV 5/5; 43/72] END criterion=entropy, max_depth=2, n_estimators=100;, score=0.637 total time=   0.0s\n",
      "[CV 1/5; 44/72] START criterion=entropy, max_depth=2, n_estimators=200..........\n",
      "[CV 1/5; 44/72] END criterion=entropy, max_depth=2, n_estimators=200;, score=0.703 total time=   0.1s\n",
      "[CV 2/5; 44/72] START criterion=entropy, max_depth=2, n_estimators=200..........\n",
      "[CV 2/5; 44/72] END criterion=entropy, max_depth=2, n_estimators=200;, score=0.667 total time=   0.1s\n",
      "[CV 3/5; 44/72] START criterion=entropy, max_depth=2, n_estimators=200..........\n",
      "[CV 3/5; 44/72] END criterion=entropy, max_depth=2, n_estimators=200;, score=0.745 total time=   0.1s\n",
      "[CV 4/5; 44/72] START criterion=entropy, max_depth=2, n_estimators=200..........\n",
      "[CV 4/5; 44/72] END criterion=entropy, max_depth=2, n_estimators=200;, score=0.703 total time=   0.1s\n",
      "[CV 5/5; 44/72] START criterion=entropy, max_depth=2, n_estimators=200..........\n",
      "[CV 5/5; 44/72] END criterion=entropy, max_depth=2, n_estimators=200;, score=0.677 total time=   0.1s\n",
      "[CV 1/5; 45/72] START criterion=entropy, max_depth=2, n_estimators=250..........\n",
      "[CV 1/5; 45/72] END criterion=entropy, max_depth=2, n_estimators=250;, score=0.708 total time=   0.1s\n",
      "[CV 2/5; 45/72] START criterion=entropy, max_depth=2, n_estimators=250..........\n",
      "[CV 2/5; 45/72] END criterion=entropy, max_depth=2, n_estimators=250;, score=0.665 total time=   0.1s\n",
      "[CV 3/5; 45/72] START criterion=entropy, max_depth=2, n_estimators=250..........\n",
      "[CV 3/5; 45/72] END criterion=entropy, max_depth=2, n_estimators=250;, score=0.670 total time=   0.1s\n",
      "[CV 4/5; 45/72] START criterion=entropy, max_depth=2, n_estimators=250..........\n",
      "[CV 4/5; 45/72] END criterion=entropy, max_depth=2, n_estimators=250;, score=0.715 total time=   0.1s\n",
      "[CV 5/5; 45/72] START criterion=entropy, max_depth=2, n_estimators=250..........\n",
      "[CV 5/5; 45/72] END criterion=entropy, max_depth=2, n_estimators=250;, score=0.695 total time=   0.1s\n",
      "[CV 1/5; 46/72] START criterion=entropy, max_depth=2, n_estimators=300..........\n",
      "[CV 1/5; 46/72] END criterion=entropy, max_depth=2, n_estimators=300;, score=0.710 total time=   0.2s\n",
      "[CV 2/5; 46/72] START criterion=entropy, max_depth=2, n_estimators=300..........\n",
      "[CV 2/5; 46/72] END criterion=entropy, max_depth=2, n_estimators=300;, score=0.660 total time=   0.2s\n",
      "[CV 3/5; 46/72] START criterion=entropy, max_depth=2, n_estimators=300..........\n",
      "[CV 3/5; 46/72] END criterion=entropy, max_depth=2, n_estimators=300;, score=0.698 total time=   0.2s\n",
      "[CV 4/5; 46/72] START criterion=entropy, max_depth=2, n_estimators=300..........\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 46/72] END criterion=entropy, max_depth=2, n_estimators=300;, score=0.705 total time=   0.2s\n",
      "[CV 5/5; 46/72] START criterion=entropy, max_depth=2, n_estimators=300..........\n",
      "[CV 5/5; 46/72] END criterion=entropy, max_depth=2, n_estimators=300;, score=0.665 total time=   0.2s\n",
      "[CV 1/5; 47/72] START criterion=entropy, max_depth=2, n_estimators=400..........\n",
      "[CV 1/5; 47/72] END criterion=entropy, max_depth=2, n_estimators=400;, score=0.637 total time=   0.2s\n",
      "[CV 2/5; 47/72] START criterion=entropy, max_depth=2, n_estimators=400..........\n",
      "[CV 2/5; 47/72] END criterion=entropy, max_depth=2, n_estimators=400;, score=0.620 total time=   0.3s\n",
      "[CV 3/5; 47/72] START criterion=entropy, max_depth=2, n_estimators=400..........\n",
      "[CV 3/5; 47/72] END criterion=entropy, max_depth=2, n_estimators=400;, score=0.703 total time=   0.2s\n",
      "[CV 4/5; 47/72] START criterion=entropy, max_depth=2, n_estimators=400..........\n",
      "[CV 4/5; 47/72] END criterion=entropy, max_depth=2, n_estimators=400;, score=0.703 total time=   0.2s\n",
      "[CV 5/5; 47/72] START criterion=entropy, max_depth=2, n_estimators=400..........\n",
      "[CV 5/5; 47/72] END criterion=entropy, max_depth=2, n_estimators=400;, score=0.650 total time=   0.2s\n",
      "[CV 1/5; 48/72] START criterion=entropy, max_depth=2, n_estimators=500..........\n",
      "[CV 1/5; 48/72] END criterion=entropy, max_depth=2, n_estimators=500;, score=0.675 total time=   0.2s\n",
      "[CV 2/5; 48/72] START criterion=entropy, max_depth=2, n_estimators=500..........\n",
      "[CV 2/5; 48/72] END criterion=entropy, max_depth=2, n_estimators=500;, score=0.672 total time=   0.2s\n",
      "[CV 3/5; 48/72] START criterion=entropy, max_depth=2, n_estimators=500..........\n",
      "[CV 3/5; 48/72] END criterion=entropy, max_depth=2, n_estimators=500;, score=0.700 total time=   0.2s\n",
      "[CV 4/5; 48/72] START criterion=entropy, max_depth=2, n_estimators=500..........\n",
      "[CV 4/5; 48/72] END criterion=entropy, max_depth=2, n_estimators=500;, score=0.693 total time=   0.2s\n",
      "[CV 5/5; 48/72] START criterion=entropy, max_depth=2, n_estimators=500..........\n",
      "[CV 5/5; 48/72] END criterion=entropy, max_depth=2, n_estimators=500;, score=0.682 total time=   0.2s\n",
      "[CV 1/5; 49/72] START criterion=entropy, max_depth=5, n_estimators=100..........\n",
      "[CV 1/5; 49/72] END criterion=entropy, max_depth=5, n_estimators=100;, score=0.845 total time=   0.0s\n",
      "[CV 2/5; 49/72] START criterion=entropy, max_depth=5, n_estimators=100..........\n",
      "[CV 2/5; 49/72] END criterion=entropy, max_depth=5, n_estimators=100;, score=0.823 total time=   0.0s\n",
      "[CV 3/5; 49/72] START criterion=entropy, max_depth=5, n_estimators=100..........\n",
      "[CV 3/5; 49/72] END criterion=entropy, max_depth=5, n_estimators=100;, score=0.877 total time=   0.0s\n",
      "[CV 4/5; 49/72] START criterion=entropy, max_depth=5, n_estimators=100..........\n",
      "[CV 4/5; 49/72] END criterion=entropy, max_depth=5, n_estimators=100;, score=0.820 total time=   0.0s\n",
      "[CV 5/5; 49/72] START criterion=entropy, max_depth=5, n_estimators=100..........\n",
      "[CV 5/5; 49/72] END criterion=entropy, max_depth=5, n_estimators=100;, score=0.838 total time=   0.0s\n",
      "[CV 1/5; 50/72] START criterion=entropy, max_depth=5, n_estimators=200..........\n",
      "[CV 1/5; 50/72] END criterion=entropy, max_depth=5, n_estimators=200;, score=0.835 total time=   0.1s\n",
      "[CV 2/5; 50/72] START criterion=entropy, max_depth=5, n_estimators=200..........\n",
      "[CV 2/5; 50/72] END criterion=entropy, max_depth=5, n_estimators=200;, score=0.823 total time=   0.1s\n",
      "[CV 3/5; 50/72] START criterion=entropy, max_depth=5, n_estimators=200..........\n",
      "[CV 3/5; 50/72] END criterion=entropy, max_depth=5, n_estimators=200;, score=0.863 total time=   0.1s\n",
      "[CV 4/5; 50/72] START criterion=entropy, max_depth=5, n_estimators=200..........\n",
      "[CV 4/5; 50/72] END criterion=entropy, max_depth=5, n_estimators=200;, score=0.838 total time=   0.1s\n",
      "[CV 5/5; 50/72] START criterion=entropy, max_depth=5, n_estimators=200..........\n",
      "[CV 5/5; 50/72] END criterion=entropy, max_depth=5, n_estimators=200;, score=0.833 total time=   0.1s\n",
      "[CV 1/5; 51/72] START criterion=entropy, max_depth=5, n_estimators=250..........\n",
      "[CV 1/5; 51/72] END criterion=entropy, max_depth=5, n_estimators=250;, score=0.825 total time=   0.1s\n",
      "[CV 2/5; 51/72] START criterion=entropy, max_depth=5, n_estimators=250..........\n",
      "[CV 2/5; 51/72] END criterion=entropy, max_depth=5, n_estimators=250;, score=0.818 total time=   0.1s\n",
      "[CV 3/5; 51/72] START criterion=entropy, max_depth=5, n_estimators=250..........\n",
      "[CV 3/5; 51/72] END criterion=entropy, max_depth=5, n_estimators=250;, score=0.853 total time=   0.1s\n",
      "[CV 4/5; 51/72] START criterion=entropy, max_depth=5, n_estimators=250..........\n",
      "[CV 4/5; 51/72] END criterion=entropy, max_depth=5, n_estimators=250;, score=0.845 total time=   0.1s\n",
      "[CV 5/5; 51/72] START criterion=entropy, max_depth=5, n_estimators=250..........\n",
      "[CV 5/5; 51/72] END criterion=entropy, max_depth=5, n_estimators=250;, score=0.843 total time=   0.1s\n",
      "[CV 1/5; 52/72] START criterion=entropy, max_depth=5, n_estimators=300..........\n",
      "[CV 1/5; 52/72] END criterion=entropy, max_depth=5, n_estimators=300;, score=0.845 total time=   0.2s\n",
      "[CV 2/5; 52/72] START criterion=entropy, max_depth=5, n_estimators=300..........\n",
      "[CV 2/5; 52/72] END criterion=entropy, max_depth=5, n_estimators=300;, score=0.840 total time=   0.2s\n",
      "[CV 3/5; 52/72] START criterion=entropy, max_depth=5, n_estimators=300..........\n",
      "[CV 3/5; 52/72] END criterion=entropy, max_depth=5, n_estimators=300;, score=0.868 total time=   0.2s\n",
      "[CV 4/5; 52/72] START criterion=entropy, max_depth=5, n_estimators=300..........\n",
      "[CV 4/5; 52/72] END criterion=entropy, max_depth=5, n_estimators=300;, score=0.843 total time=   0.2s\n",
      "[CV 5/5; 52/72] START criterion=entropy, max_depth=5, n_estimators=300..........\n",
      "[CV 5/5; 52/72] END criterion=entropy, max_depth=5, n_estimators=300;, score=0.835 total time=   0.2s\n",
      "[CV 1/5; 53/72] START criterion=entropy, max_depth=5, n_estimators=400..........\n",
      "[CV 1/5; 53/72] END criterion=entropy, max_depth=5, n_estimators=400;, score=0.833 total time=   0.2s\n",
      "[CV 2/5; 53/72] START criterion=entropy, max_depth=5, n_estimators=400..........\n",
      "[CV 2/5; 53/72] END criterion=entropy, max_depth=5, n_estimators=400;, score=0.828 total time=   0.3s\n",
      "[CV 3/5; 53/72] START criterion=entropy, max_depth=5, n_estimators=400..........\n",
      "[CV 3/5; 53/72] END criterion=entropy, max_depth=5, n_estimators=400;, score=0.865 total time=   0.2s\n",
      "[CV 4/5; 53/72] START criterion=entropy, max_depth=5, n_estimators=400..........\n",
      "[CV 4/5; 53/72] END criterion=entropy, max_depth=5, n_estimators=400;, score=0.838 total time=   0.2s\n",
      "[CV 5/5; 53/72] START criterion=entropy, max_depth=5, n_estimators=400..........\n",
      "[CV 5/5; 53/72] END criterion=entropy, max_depth=5, n_estimators=400;, score=0.843 total time=   0.2s\n",
      "[CV 1/5; 54/72] START criterion=entropy, max_depth=5, n_estimators=500..........\n",
      "[CV 1/5; 54/72] END criterion=entropy, max_depth=5, n_estimators=500;, score=0.840 total time=   0.3s\n",
      "[CV 2/5; 54/72] START criterion=entropy, max_depth=5, n_estimators=500..........\n",
      "[CV 2/5; 54/72] END criterion=entropy, max_depth=5, n_estimators=500;, score=0.850 total time=   0.3s\n",
      "[CV 3/5; 54/72] START criterion=entropy, max_depth=5, n_estimators=500..........\n",
      "[CV 3/5; 54/72] END criterion=entropy, max_depth=5, n_estimators=500;, score=0.868 total time=   0.3s\n",
      "[CV 4/5; 54/72] START criterion=entropy, max_depth=5, n_estimators=500..........\n",
      "[CV 4/5; 54/72] END criterion=entropy, max_depth=5, n_estimators=500;, score=0.835 total time=   0.3s\n",
      "[CV 5/5; 54/72] START criterion=entropy, max_depth=5, n_estimators=500..........\n",
      "[CV 5/5; 54/72] END criterion=entropy, max_depth=5, n_estimators=500;, score=0.840 total time=   0.3s\n",
      "[CV 1/5; 55/72] START criterion=entropy, max_depth=7, n_estimators=100..........\n",
      "[CV 1/5; 55/72] END criterion=entropy, max_depth=7, n_estimators=100;, score=0.875 total time=   0.0s\n",
      "[CV 2/5; 55/72] START criterion=entropy, max_depth=7, n_estimators=100..........\n",
      "[CV 2/5; 55/72] END criterion=entropy, max_depth=7, n_estimators=100;, score=0.865 total time=   0.0s\n",
      "[CV 3/5; 55/72] START criterion=entropy, max_depth=7, n_estimators=100..........\n",
      "[CV 3/5; 55/72] END criterion=entropy, max_depth=7, n_estimators=100;, score=0.887 total time=   0.0s\n",
      "[CV 4/5; 55/72] START criterion=entropy, max_depth=7, n_estimators=100..........\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 55/72] END criterion=entropy, max_depth=7, n_estimators=100;, score=0.855 total time=   0.0s\n",
      "[CV 5/5; 55/72] START criterion=entropy, max_depth=7, n_estimators=100..........\n",
      "[CV 5/5; 55/72] END criterion=entropy, max_depth=7, n_estimators=100;, score=0.850 total time=   0.0s\n",
      "[CV 1/5; 56/72] START criterion=entropy, max_depth=7, n_estimators=200..........\n",
      "[CV 1/5; 56/72] END criterion=entropy, max_depth=7, n_estimators=200;, score=0.875 total time=   0.1s\n",
      "[CV 2/5; 56/72] START criterion=entropy, max_depth=7, n_estimators=200..........\n",
      "[CV 2/5; 56/72] END criterion=entropy, max_depth=7, n_estimators=200;, score=0.858 total time=   0.1s\n",
      "[CV 3/5; 56/72] START criterion=entropy, max_depth=7, n_estimators=200..........\n",
      "[CV 3/5; 56/72] END criterion=entropy, max_depth=7, n_estimators=200;, score=0.897 total time=   0.1s\n",
      "[CV 4/5; 56/72] START criterion=entropy, max_depth=7, n_estimators=200..........\n",
      "[CV 4/5; 56/72] END criterion=entropy, max_depth=7, n_estimators=200;, score=0.855 total time=   0.1s\n",
      "[CV 5/5; 56/72] START criterion=entropy, max_depth=7, n_estimators=200..........\n",
      "[CV 5/5; 56/72] END criterion=entropy, max_depth=7, n_estimators=200;, score=0.843 total time=   0.1s\n",
      "[CV 1/5; 57/72] START criterion=entropy, max_depth=7, n_estimators=250..........\n",
      "[CV 1/5; 57/72] END criterion=entropy, max_depth=7, n_estimators=250;, score=0.865 total time=   0.1s\n",
      "[CV 2/5; 57/72] START criterion=entropy, max_depth=7, n_estimators=250..........\n",
      "[CV 2/5; 57/72] END criterion=entropy, max_depth=7, n_estimators=250;, score=0.870 total time=   0.1s\n",
      "[CV 3/5; 57/72] START criterion=entropy, max_depth=7, n_estimators=250..........\n",
      "[CV 3/5; 57/72] END criterion=entropy, max_depth=7, n_estimators=250;, score=0.907 total time=   0.1s\n",
      "[CV 4/5; 57/72] START criterion=entropy, max_depth=7, n_estimators=250..........\n",
      "[CV 4/5; 57/72] END criterion=entropy, max_depth=7, n_estimators=250;, score=0.843 total time=   0.1s\n",
      "[CV 5/5; 57/72] START criterion=entropy, max_depth=7, n_estimators=250..........\n",
      "[CV 5/5; 57/72] END criterion=entropy, max_depth=7, n_estimators=250;, score=0.848 total time=   0.1s\n",
      "[CV 1/5; 58/72] START criterion=entropy, max_depth=7, n_estimators=300..........\n",
      "[CV 1/5; 58/72] END criterion=entropy, max_depth=7, n_estimators=300;, score=0.865 total time=   0.2s\n",
      "[CV 2/5; 58/72] START criterion=entropy, max_depth=7, n_estimators=300..........\n",
      "[CV 2/5; 58/72] END criterion=entropy, max_depth=7, n_estimators=300;, score=0.863 total time=   0.2s\n",
      "[CV 3/5; 58/72] START criterion=entropy, max_depth=7, n_estimators=300..........\n",
      "[CV 3/5; 58/72] END criterion=entropy, max_depth=7, n_estimators=300;, score=0.890 total time=   0.2s\n",
      "[CV 4/5; 58/72] START criterion=entropy, max_depth=7, n_estimators=300..........\n",
      "[CV 4/5; 58/72] END criterion=entropy, max_depth=7, n_estimators=300;, score=0.853 total time=   0.2s\n",
      "[CV 5/5; 58/72] START criterion=entropy, max_depth=7, n_estimators=300..........\n",
      "[CV 5/5; 58/72] END criterion=entropy, max_depth=7, n_estimators=300;, score=0.850 total time=   0.3s\n",
      "[CV 1/5; 59/72] START criterion=entropy, max_depth=7, n_estimators=400..........\n",
      "[CV 1/5; 59/72] END criterion=entropy, max_depth=7, n_estimators=400;, score=0.860 total time=   0.2s\n",
      "[CV 2/5; 59/72] START criterion=entropy, max_depth=7, n_estimators=400..........\n",
      "[CV 2/5; 59/72] END criterion=entropy, max_depth=7, n_estimators=400;, score=0.865 total time=   0.3s\n",
      "[CV 3/5; 59/72] START criterion=entropy, max_depth=7, n_estimators=400..........\n",
      "[CV 3/5; 59/72] END criterion=entropy, max_depth=7, n_estimators=400;, score=0.895 total time=   0.2s\n",
      "[CV 4/5; 59/72] START criterion=entropy, max_depth=7, n_estimators=400..........\n",
      "[CV 4/5; 59/72] END criterion=entropy, max_depth=7, n_estimators=400;, score=0.855 total time=   0.2s\n",
      "[CV 5/5; 59/72] START criterion=entropy, max_depth=7, n_estimators=400..........\n",
      "[CV 5/5; 59/72] END criterion=entropy, max_depth=7, n_estimators=400;, score=0.853 total time=   0.2s\n",
      "[CV 1/5; 60/72] START criterion=entropy, max_depth=7, n_estimators=500..........\n",
      "[CV 1/5; 60/72] END criterion=entropy, max_depth=7, n_estimators=500;, score=0.873 total time=   0.3s\n",
      "[CV 2/5; 60/72] START criterion=entropy, max_depth=7, n_estimators=500..........\n",
      "[CV 2/5; 60/72] END criterion=entropy, max_depth=7, n_estimators=500;, score=0.853 total time=   0.3s\n",
      "[CV 3/5; 60/72] START criterion=entropy, max_depth=7, n_estimators=500..........\n",
      "[CV 3/5; 60/72] END criterion=entropy, max_depth=7, n_estimators=500;, score=0.897 total time=   0.3s\n",
      "[CV 4/5; 60/72] START criterion=entropy, max_depth=7, n_estimators=500..........\n",
      "[CV 4/5; 60/72] END criterion=entropy, max_depth=7, n_estimators=500;, score=0.853 total time=   0.3s\n",
      "[CV 5/5; 60/72] START criterion=entropy, max_depth=7, n_estimators=500..........\n",
      "[CV 5/5; 60/72] END criterion=entropy, max_depth=7, n_estimators=500;, score=0.863 total time=   0.3s\n",
      "[CV 1/5; 61/72] START criterion=entropy, max_depth=11, n_estimators=100.........\n",
      "[CV 1/5; 61/72] END criterion=entropy, max_depth=11, n_estimators=100;, score=0.868 total time=   0.0s\n",
      "[CV 2/5; 61/72] START criterion=entropy, max_depth=11, n_estimators=100.........\n",
      "[CV 2/5; 61/72] END criterion=entropy, max_depth=11, n_estimators=100;, score=0.890 total time=   0.0s\n",
      "[CV 3/5; 61/72] START criterion=entropy, max_depth=11, n_estimators=100.........\n",
      "[CV 3/5; 61/72] END criterion=entropy, max_depth=11, n_estimators=100;, score=0.892 total time=   0.0s\n",
      "[CV 4/5; 61/72] START criterion=entropy, max_depth=11, n_estimators=100.........\n",
      "[CV 4/5; 61/72] END criterion=entropy, max_depth=11, n_estimators=100;, score=0.868 total time=   0.0s\n",
      "[CV 5/5; 61/72] START criterion=entropy, max_depth=11, n_estimators=100.........\n",
      "[CV 5/5; 61/72] END criterion=entropy, max_depth=11, n_estimators=100;, score=0.860 total time=   0.0s\n",
      "[CV 1/5; 62/72] START criterion=entropy, max_depth=11, n_estimators=200.........\n",
      "[CV 1/5; 62/72] END criterion=entropy, max_depth=11, n_estimators=200;, score=0.887 total time=   0.1s\n",
      "[CV 2/5; 62/72] START criterion=entropy, max_depth=11, n_estimators=200.........\n",
      "[CV 2/5; 62/72] END criterion=entropy, max_depth=11, n_estimators=200;, score=0.868 total time=   0.1s\n",
      "[CV 3/5; 62/72] START criterion=entropy, max_depth=11, n_estimators=200.........\n",
      "[CV 3/5; 62/72] END criterion=entropy, max_depth=11, n_estimators=200;, score=0.895 total time=   0.1s\n",
      "[CV 4/5; 62/72] START criterion=entropy, max_depth=11, n_estimators=200.........\n",
      "[CV 4/5; 62/72] END criterion=entropy, max_depth=11, n_estimators=200;, score=0.882 total time=   0.1s\n",
      "[CV 5/5; 62/72] START criterion=entropy, max_depth=11, n_estimators=200.........\n",
      "[CV 5/5; 62/72] END criterion=entropy, max_depth=11, n_estimators=200;, score=0.863 total time=   0.1s\n",
      "[CV 1/5; 63/72] START criterion=entropy, max_depth=11, n_estimators=250.........\n",
      "[CV 1/5; 63/72] END criterion=entropy, max_depth=11, n_estimators=250;, score=0.875 total time=   0.1s\n",
      "[CV 2/5; 63/72] START criterion=entropy, max_depth=11, n_estimators=250.........\n",
      "[CV 2/5; 63/72] END criterion=entropy, max_depth=11, n_estimators=250;, score=0.887 total time=   0.1s\n",
      "[CV 3/5; 63/72] START criterion=entropy, max_depth=11, n_estimators=250.........\n",
      "[CV 3/5; 63/72] END criterion=entropy, max_depth=11, n_estimators=250;, score=0.897 total time=   0.1s\n",
      "[CV 4/5; 63/72] START criterion=entropy, max_depth=11, n_estimators=250.........\n",
      "[CV 4/5; 63/72] END criterion=entropy, max_depth=11, n_estimators=250;, score=0.873 total time=   0.1s\n",
      "[CV 5/5; 63/72] START criterion=entropy, max_depth=11, n_estimators=250.........\n",
      "[CV 5/5; 63/72] END criterion=entropy, max_depth=11, n_estimators=250;, score=0.877 total time=   0.1s\n",
      "[CV 1/5; 64/72] START criterion=entropy, max_depth=11, n_estimators=300.........\n",
      "[CV 1/5; 64/72] END criterion=entropy, max_depth=11, n_estimators=300;, score=0.890 total time=   0.2s\n",
      "[CV 2/5; 64/72] START criterion=entropy, max_depth=11, n_estimators=300.........\n",
      "[CV 2/5; 64/72] END criterion=entropy, max_depth=11, n_estimators=300;, score=0.887 total time=   0.3s\n",
      "[CV 3/5; 64/72] START criterion=entropy, max_depth=11, n_estimators=300.........\n",
      "[CV 3/5; 64/72] END criterion=entropy, max_depth=11, n_estimators=300;, score=0.895 total time=   0.2s\n",
      "[CV 4/5; 64/72] START criterion=entropy, max_depth=11, n_estimators=300.........\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 64/72] END criterion=entropy, max_depth=11, n_estimators=300;, score=0.863 total time=   0.2s\n",
      "[CV 5/5; 64/72] START criterion=entropy, max_depth=11, n_estimators=300.........\n",
      "[CV 5/5; 64/72] END criterion=entropy, max_depth=11, n_estimators=300;, score=0.875 total time=   0.2s\n",
      "[CV 1/5; 65/72] START criterion=entropy, max_depth=11, n_estimators=400.........\n",
      "[CV 1/5; 65/72] END criterion=entropy, max_depth=11, n_estimators=400;, score=0.887 total time=   0.2s\n",
      "[CV 2/5; 65/72] START criterion=entropy, max_depth=11, n_estimators=400.........\n",
      "[CV 2/5; 65/72] END criterion=entropy, max_depth=11, n_estimators=400;, score=0.892 total time=   0.3s\n",
      "[CV 3/5; 65/72] START criterion=entropy, max_depth=11, n_estimators=400.........\n",
      "[CV 3/5; 65/72] END criterion=entropy, max_depth=11, n_estimators=400;, score=0.902 total time=   0.3s\n",
      "[CV 4/5; 65/72] START criterion=entropy, max_depth=11, n_estimators=400.........\n",
      "[CV 4/5; 65/72] END criterion=entropy, max_depth=11, n_estimators=400;, score=0.875 total time=   0.3s\n",
      "[CV 5/5; 65/72] START criterion=entropy, max_depth=11, n_estimators=400.........\n",
      "[CV 5/5; 65/72] END criterion=entropy, max_depth=11, n_estimators=400;, score=0.877 total time=   0.3s\n",
      "[CV 1/5; 66/72] START criterion=entropy, max_depth=11, n_estimators=500.........\n",
      "[CV 1/5; 66/72] END criterion=entropy, max_depth=11, n_estimators=500;, score=0.882 total time=   0.3s\n",
      "[CV 2/5; 66/72] START criterion=entropy, max_depth=11, n_estimators=500.........\n",
      "[CV 2/5; 66/72] END criterion=entropy, max_depth=11, n_estimators=500;, score=0.890 total time=   0.3s\n",
      "[CV 3/5; 66/72] START criterion=entropy, max_depth=11, n_estimators=500.........\n",
      "[CV 3/5; 66/72] END criterion=entropy, max_depth=11, n_estimators=500;, score=0.907 total time=   0.3s\n",
      "[CV 4/5; 66/72] START criterion=entropy, max_depth=11, n_estimators=500.........\n",
      "[CV 4/5; 66/72] END criterion=entropy, max_depth=11, n_estimators=500;, score=0.870 total time=   0.3s\n",
      "[CV 5/5; 66/72] START criterion=entropy, max_depth=11, n_estimators=500.........\n",
      "[CV 5/5; 66/72] END criterion=entropy, max_depth=11, n_estimators=500;, score=0.868 total time=   0.3s\n",
      "[CV 1/5; 67/72] START criterion=entropy, max_depth=15, n_estimators=100.........\n",
      "[CV 1/5; 67/72] END criterion=entropy, max_depth=15, n_estimators=100;, score=0.885 total time=   0.0s\n",
      "[CV 2/5; 67/72] START criterion=entropy, max_depth=15, n_estimators=100.........\n",
      "[CV 2/5; 67/72] END criterion=entropy, max_depth=15, n_estimators=100;, score=0.875 total time=   0.0s\n",
      "[CV 3/5; 67/72] START criterion=entropy, max_depth=15, n_estimators=100.........\n",
      "[CV 3/5; 67/72] END criterion=entropy, max_depth=15, n_estimators=100;, score=0.885 total time=   0.0s\n",
      "[CV 4/5; 67/72] START criterion=entropy, max_depth=15, n_estimators=100.........\n",
      "[CV 4/5; 67/72] END criterion=entropy, max_depth=15, n_estimators=100;, score=0.873 total time=   0.0s\n",
      "[CV 5/5; 67/72] START criterion=entropy, max_depth=15, n_estimators=100.........\n",
      "[CV 5/5; 67/72] END criterion=entropy, max_depth=15, n_estimators=100;, score=0.870 total time=   0.0s\n",
      "[CV 1/5; 68/72] START criterion=entropy, max_depth=15, n_estimators=200.........\n",
      "[CV 1/5; 68/72] END criterion=entropy, max_depth=15, n_estimators=200;, score=0.875 total time=   0.1s\n",
      "[CV 2/5; 68/72] START criterion=entropy, max_depth=15, n_estimators=200.........\n",
      "[CV 2/5; 68/72] END criterion=entropy, max_depth=15, n_estimators=200;, score=0.892 total time=   0.1s\n",
      "[CV 3/5; 68/72] START criterion=entropy, max_depth=15, n_estimators=200.........\n",
      "[CV 3/5; 68/72] END criterion=entropy, max_depth=15, n_estimators=200;, score=0.907 total time=   0.1s\n",
      "[CV 4/5; 68/72] START criterion=entropy, max_depth=15, n_estimators=200.........\n",
      "[CV 4/5; 68/72] END criterion=entropy, max_depth=15, n_estimators=200;, score=0.863 total time=   0.1s\n",
      "[CV 5/5; 68/72] START criterion=entropy, max_depth=15, n_estimators=200.........\n",
      "[CV 5/5; 68/72] END criterion=entropy, max_depth=15, n_estimators=200;, score=0.860 total time=   0.1s\n",
      "[CV 1/5; 69/72] START criterion=entropy, max_depth=15, n_estimators=250.........\n",
      "[CV 1/5; 69/72] END criterion=entropy, max_depth=15, n_estimators=250;, score=0.885 total time=   0.1s\n",
      "[CV 2/5; 69/72] START criterion=entropy, max_depth=15, n_estimators=250.........\n",
      "[CV 2/5; 69/72] END criterion=entropy, max_depth=15, n_estimators=250;, score=0.900 total time=   0.1s\n",
      "[CV 3/5; 69/72] START criterion=entropy, max_depth=15, n_estimators=250.........\n",
      "[CV 3/5; 69/72] END criterion=entropy, max_depth=15, n_estimators=250;, score=0.902 total time=   0.1s\n",
      "[CV 4/5; 69/72] START criterion=entropy, max_depth=15, n_estimators=250.........\n",
      "[CV 4/5; 69/72] END criterion=entropy, max_depth=15, n_estimators=250;, score=0.875 total time=   0.1s\n",
      "[CV 5/5; 69/72] START criterion=entropy, max_depth=15, n_estimators=250.........\n",
      "[CV 5/5; 69/72] END criterion=entropy, max_depth=15, n_estimators=250;, score=0.877 total time=   0.2s\n",
      "[CV 1/5; 70/72] START criterion=entropy, max_depth=15, n_estimators=300.........\n",
      "[CV 1/5; 70/72] END criterion=entropy, max_depth=15, n_estimators=300;, score=0.880 total time=   0.2s\n",
      "[CV 2/5; 70/72] START criterion=entropy, max_depth=15, n_estimators=300.........\n",
      "[CV 2/5; 70/72] END criterion=entropy, max_depth=15, n_estimators=300;, score=0.902 total time=   0.2s\n",
      "[CV 3/5; 70/72] START criterion=entropy, max_depth=15, n_estimators=300.........\n",
      "[CV 3/5; 70/72] END criterion=entropy, max_depth=15, n_estimators=300;, score=0.897 total time=   0.2s\n",
      "[CV 4/5; 70/72] START criterion=entropy, max_depth=15, n_estimators=300.........\n",
      "[CV 4/5; 70/72] END criterion=entropy, max_depth=15, n_estimators=300;, score=0.868 total time=   0.2s\n",
      "[CV 5/5; 70/72] START criterion=entropy, max_depth=15, n_estimators=300.........\n",
      "[CV 5/5; 70/72] END criterion=entropy, max_depth=15, n_estimators=300;, score=0.870 total time=   0.2s\n",
      "[CV 1/5; 71/72] START criterion=entropy, max_depth=15, n_estimators=400.........\n",
      "[CV 1/5; 71/72] END criterion=entropy, max_depth=15, n_estimators=400;, score=0.882 total time=   0.3s\n",
      "[CV 2/5; 71/72] START criterion=entropy, max_depth=15, n_estimators=400.........\n",
      "[CV 2/5; 71/72] END criterion=entropy, max_depth=15, n_estimators=400;, score=0.895 total time=   0.3s\n",
      "[CV 3/5; 71/72] START criterion=entropy, max_depth=15, n_estimators=400.........\n",
      "[CV 3/5; 71/72] END criterion=entropy, max_depth=15, n_estimators=400;, score=0.907 total time=   0.3s\n",
      "[CV 4/5; 71/72] START criterion=entropy, max_depth=15, n_estimators=400.........\n",
      "[CV 4/5; 71/72] END criterion=entropy, max_depth=15, n_estimators=400;, score=0.870 total time=   0.3s\n",
      "[CV 5/5; 71/72] START criterion=entropy, max_depth=15, n_estimators=400.........\n",
      "[CV 5/5; 71/72] END criterion=entropy, max_depth=15, n_estimators=400;, score=0.875 total time=   0.3s\n",
      "[CV 1/5; 72/72] START criterion=entropy, max_depth=15, n_estimators=500.........\n",
      "[CV 1/5; 72/72] END criterion=entropy, max_depth=15, n_estimators=500;, score=0.887 total time=   0.3s\n",
      "[CV 2/5; 72/72] START criterion=entropy, max_depth=15, n_estimators=500.........\n",
      "[CV 2/5; 72/72] END criterion=entropy, max_depth=15, n_estimators=500;, score=0.897 total time=   0.3s\n",
      "[CV 3/5; 72/72] START criterion=entropy, max_depth=15, n_estimators=500.........\n",
      "[CV 3/5; 72/72] END criterion=entropy, max_depth=15, n_estimators=500;, score=0.907 total time=   0.3s\n",
      "[CV 4/5; 72/72] START criterion=entropy, max_depth=15, n_estimators=500.........\n",
      "[CV 4/5; 72/72] END criterion=entropy, max_depth=15, n_estimators=500;, score=0.870 total time=   0.3s\n",
      "[CV 5/5; 72/72] START criterion=entropy, max_depth=15, n_estimators=500.........\n",
      "[CV 5/5; 72/72] END criterion=entropy, max_depth=15, n_estimators=500;, score=0.875 total time=   0.3s\n",
      "Best score: 0.8879999999999999\n",
      "Best parameters set:\n",
      "\tcriterion: entropy\n",
      "\tmax_depth: 15\n",
      "\tn_estimators: 250\n"
     ]
    }
   ],
   "source": [
    "# rf_grid_search.py \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn import ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    \n",
    "    # 读取数据\n",
    "    df = pd.read_csv(\"data/mobile_train.csv\")\n",
    "    \n",
    "    # 删除 price_range 列\n",
    "    X = df.drop(\"price_range\", axis=1).values\n",
    "    # 取目标变量 y（\"price_range\"列）\n",
    "    y = df.price_range.values\n",
    "    \n",
    "    # 创建随机森林分类器，使用所有可用的 CPU 核心进行训练\n",
    "    classifier = ensemble.RandomForestClassifier(n_jobs=-1) \n",
    "    \n",
    "    # 定义要进行网格搜索的参数网格\n",
    "    param_grid = {\n",
    "        \"n_estimators\": [100, 200, 250, 300, 400, 500], \n",
    "        \"max_depth\": [1, 2, 5, 7, 11, 15],\n",
    "        \"criterion\": [\"gini\", \"entropy\"] \n",
    "    }\n",
    "    \n",
    "    # 创建 GridSearchCV 对象 model，用于在参数网格上进行网格搜索\n",
    "    model = model_selection.GridSearchCV( \n",
    "        estimator=classifier,\n",
    "        param_grid=param_grid, \n",
    "        scoring=\"accuracy\", \n",
    "        verbose=10,\n",
    "        n_jobs=1, \n",
    "        cv=5\n",
    "    )\n",
    "    \n",
    "    # 使用网格搜索对象 model 拟合数据，寻找最佳参数组合\n",
    "    model.fit(X, y)\n",
    "    # 打印出最佳模型的最佳准确度分数\n",
    "    print(f\"Best score: {model.best_score_}\") \n",
    "    # 打印最佳参数集合\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = model.best_estimator_.get_params() \n",
    "    \n",
    "    for param_name in sorted(param_grid.keys()):\n",
    "        print(f\"\\t{param_name}: {best_parameters[param_name]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6efb050",
   "metadata": {},
   "source": [
    "## RandomizedSearchCV(随机搜索)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec237a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5; 1/20] START criterion=gini, max_depth=23, n_estimators=700.............\n",
      "[CV 1/5; 1/20] END criterion=gini, max_depth=23, n_estimators=700;, score=0.885 total time=   3.4s\n",
      "[CV 2/5; 1/20] START criterion=gini, max_depth=23, n_estimators=700.............\n",
      "[CV 2/5; 1/20] END criterion=gini, max_depth=23, n_estimators=700;, score=0.890 total time=   0.6s\n",
      "[CV 3/5; 1/20] START criterion=gini, max_depth=23, n_estimators=700.............\n",
      "[CV 3/5; 1/20] END criterion=gini, max_depth=23, n_estimators=700;, score=0.895 total time=   0.5s\n",
      "[CV 4/5; 1/20] START criterion=gini, max_depth=23, n_estimators=700.............\n",
      "[CV 4/5; 1/20] END criterion=gini, max_depth=23, n_estimators=700;, score=0.880 total time=   0.5s\n",
      "[CV 5/5; 1/20] START criterion=gini, max_depth=23, n_estimators=700.............\n",
      "[CV 5/5; 1/20] END criterion=gini, max_depth=23, n_estimators=700;, score=0.863 total time=   0.5s\n",
      "[CV 1/5; 2/20] START criterion=entropy, max_depth=9, n_estimators=400...........\n",
      "[CV 1/5; 2/20] END criterion=entropy, max_depth=9, n_estimators=400;, score=0.882 total time=   0.2s\n",
      "[CV 2/5; 2/20] START criterion=entropy, max_depth=9, n_estimators=400...........\n",
      "[CV 2/5; 2/20] END criterion=entropy, max_depth=9, n_estimators=400;, score=0.887 total time=   0.2s\n",
      "[CV 3/5; 2/20] START criterion=entropy, max_depth=9, n_estimators=400...........\n",
      "[CV 3/5; 2/20] END criterion=entropy, max_depth=9, n_estimators=400;, score=0.900 total time=   0.2s\n",
      "[CV 4/5; 2/20] START criterion=entropy, max_depth=9, n_estimators=400...........\n",
      "[CV 4/5; 2/20] END criterion=entropy, max_depth=9, n_estimators=400;, score=0.868 total time=   0.2s\n",
      "[CV 5/5; 2/20] START criterion=entropy, max_depth=9, n_estimators=400...........\n",
      "[CV 5/5; 2/20] END criterion=entropy, max_depth=9, n_estimators=400;, score=0.860 total time=   0.2s\n",
      "[CV 1/5; 3/20] START criterion=gini, max_depth=28, n_estimators=200.............\n",
      "[CV 1/5; 3/20] END criterion=gini, max_depth=28, n_estimators=200;, score=0.877 total time=   0.1s\n",
      "[CV 2/5; 3/20] START criterion=gini, max_depth=28, n_estimators=200.............\n",
      "[CV 2/5; 3/20] END criterion=gini, max_depth=28, n_estimators=200;, score=0.892 total time=   0.1s\n",
      "[CV 3/5; 3/20] START criterion=gini, max_depth=28, n_estimators=200.............\n",
      "[CV 3/5; 3/20] END criterion=gini, max_depth=28, n_estimators=200;, score=0.895 total time=   0.1s\n",
      "[CV 4/5; 3/20] START criterion=gini, max_depth=28, n_estimators=200.............\n",
      "[CV 4/5; 3/20] END criterion=gini, max_depth=28, n_estimators=200;, score=0.880 total time=   0.1s\n",
      "[CV 5/5; 3/20] START criterion=gini, max_depth=28, n_estimators=200.............\n",
      "[CV 5/5; 3/20] END criterion=gini, max_depth=28, n_estimators=200;, score=0.863 total time=   0.1s\n",
      "[CV 1/5; 4/20] START criterion=gini, max_depth=14, n_estimators=600.............\n",
      "[CV 1/5; 4/20] END criterion=gini, max_depth=14, n_estimators=600;, score=0.882 total time=   0.4s\n",
      "[CV 2/5; 4/20] START criterion=gini, max_depth=14, n_estimators=600.............\n",
      "[CV 2/5; 4/20] END criterion=gini, max_depth=14, n_estimators=600;, score=0.870 total time=   0.4s\n",
      "[CV 3/5; 4/20] START criterion=gini, max_depth=14, n_estimators=600.............\n",
      "[CV 3/5; 4/20] END criterion=gini, max_depth=14, n_estimators=600;, score=0.905 total time=   0.4s\n",
      "[CV 4/5; 4/20] START criterion=gini, max_depth=14, n_estimators=600.............\n",
      "[CV 4/5; 4/20] END criterion=gini, max_depth=14, n_estimators=600;, score=0.868 total time=   0.5s\n",
      "[CV 5/5; 4/20] START criterion=gini, max_depth=14, n_estimators=600.............\n",
      "[CV 5/5; 4/20] END criterion=gini, max_depth=14, n_estimators=600;, score=0.868 total time=   0.4s\n",
      "[CV 1/5; 5/20] START criterion=entropy, max_depth=12, n_estimators=200..........\n",
      "[CV 1/5; 5/20] END criterion=entropy, max_depth=12, n_estimators=200;, score=0.873 total time=   0.1s\n",
      "[CV 2/5; 5/20] START criterion=entropy, max_depth=12, n_estimators=200..........\n",
      "[CV 2/5; 5/20] END criterion=entropy, max_depth=12, n_estimators=200;, score=0.882 total time=   0.1s\n",
      "[CV 3/5; 5/20] START criterion=entropy, max_depth=12, n_estimators=200..........\n",
      "[CV 3/5; 5/20] END criterion=entropy, max_depth=12, n_estimators=200;, score=0.910 total time=   0.1s\n",
      "[CV 4/5; 5/20] START criterion=entropy, max_depth=12, n_estimators=200..........\n",
      "[CV 4/5; 5/20] END criterion=entropy, max_depth=12, n_estimators=200;, score=0.860 total time=   0.1s\n",
      "[CV 5/5; 5/20] START criterion=entropy, max_depth=12, n_estimators=200..........\n",
      "[CV 5/5; 5/20] END criterion=entropy, max_depth=12, n_estimators=200;, score=0.873 total time=   0.1s\n",
      "[CV 1/5; 6/20] START criterion=entropy, max_depth=13, n_estimators=600..........\n",
      "[CV 1/5; 6/20] END criterion=entropy, max_depth=13, n_estimators=600;, score=0.885 total time=   0.4s\n",
      "[CV 2/5; 6/20] START criterion=entropy, max_depth=13, n_estimators=600..........\n",
      "[CV 2/5; 6/20] END criterion=entropy, max_depth=13, n_estimators=600;, score=0.890 total time=   0.4s\n",
      "[CV 3/5; 6/20] START criterion=entropy, max_depth=13, n_estimators=600..........\n",
      "[CV 3/5; 6/20] END criterion=entropy, max_depth=13, n_estimators=600;, score=0.912 total time=   0.4s\n",
      "[CV 4/5; 6/20] START criterion=entropy, max_depth=13, n_estimators=600..........\n",
      "[CV 4/5; 6/20] END criterion=entropy, max_depth=13, n_estimators=600;, score=0.873 total time=   0.4s\n",
      "[CV 5/5; 6/20] START criterion=entropy, max_depth=13, n_estimators=600..........\n",
      "[CV 5/5; 6/20] END criterion=entropy, max_depth=13, n_estimators=600;, score=0.868 total time=   0.4s\n",
      "[CV 1/5; 7/20] START criterion=entropy, max_depth=18, n_estimators=400..........\n",
      "[CV 1/5; 7/20] END criterion=entropy, max_depth=18, n_estimators=400;, score=0.885 total time=   0.2s\n",
      "[CV 2/5; 7/20] START criterion=entropy, max_depth=18, n_estimators=400..........\n",
      "[CV 2/5; 7/20] END criterion=entropy, max_depth=18, n_estimators=400;, score=0.882 total time=   0.3s\n",
      "[CV 3/5; 7/20] START criterion=entropy, max_depth=18, n_estimators=400..........\n",
      "[CV 3/5; 7/20] END criterion=entropy, max_depth=18, n_estimators=400;, score=0.900 total time=   0.2s\n",
      "[CV 4/5; 7/20] START criterion=entropy, max_depth=18, n_estimators=400..........\n",
      "[CV 4/5; 7/20] END criterion=entropy, max_depth=18, n_estimators=400;, score=0.868 total time=   0.2s\n",
      "[CV 5/5; 7/20] START criterion=entropy, max_depth=18, n_estimators=400..........\n",
      "[CV 5/5; 7/20] END criterion=entropy, max_depth=18, n_estimators=400;, score=0.882 total time=   0.3s\n",
      "[CV 1/5; 8/20] START criterion=gini, max_depth=28, n_estimators=300.............\n",
      "[CV 1/5; 8/20] END criterion=gini, max_depth=28, n_estimators=300;, score=0.882 total time=   0.2s\n",
      "[CV 2/5; 8/20] START criterion=gini, max_depth=28, n_estimators=300.............\n",
      "[CV 2/5; 8/20] END criterion=gini, max_depth=28, n_estimators=300;, score=0.887 total time=   0.2s\n",
      "[CV 3/5; 8/20] START criterion=gini, max_depth=28, n_estimators=300.............\n",
      "[CV 3/5; 8/20] END criterion=gini, max_depth=28, n_estimators=300;, score=0.892 total time=   0.2s\n",
      "[CV 4/5; 8/20] START criterion=gini, max_depth=28, n_estimators=300.............\n",
      "[CV 4/5; 8/20] END criterion=gini, max_depth=28, n_estimators=300;, score=0.873 total time=   0.2s\n",
      "[CV 5/5; 8/20] START criterion=gini, max_depth=28, n_estimators=300.............\n",
      "[CV 5/5; 8/20] END criterion=gini, max_depth=28, n_estimators=300;, score=0.865 total time=   0.3s\n",
      "[CV 1/5; 9/20] START criterion=gini, max_depth=18, n_estimators=1200............\n",
      "[CV 1/5; 9/20] END criterion=gini, max_depth=18, n_estimators=1200;, score=0.880 total time=   1.0s\n",
      "[CV 2/5; 9/20] START criterion=gini, max_depth=18, n_estimators=1200............\n",
      "[CV 2/5; 9/20] END criterion=gini, max_depth=18, n_estimators=1200;, score=0.890 total time=   0.9s\n",
      "[CV 3/5; 9/20] START criterion=gini, max_depth=18, n_estimators=1200............\n",
      "[CV 3/5; 9/20] END criterion=gini, max_depth=18, n_estimators=1200;, score=0.890 total time=   0.9s\n",
      "[CV 4/5; 9/20] START criterion=gini, max_depth=18, n_estimators=1200............\n",
      "[CV 4/5; 9/20] END criterion=gini, max_depth=18, n_estimators=1200;, score=0.868 total time=   0.9s\n",
      "[CV 5/5; 9/20] START criterion=gini, max_depth=18, n_estimators=1200............\n",
      "[CV 5/5; 9/20] END criterion=gini, max_depth=18, n_estimators=1200;, score=0.868 total time=   0.9s\n",
      "[CV 1/5; 10/20] START criterion=gini, max_depth=24, n_estimators=900............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 10/20] END criterion=gini, max_depth=24, n_estimators=900;, score=0.882 total time=   0.7s\n",
      "[CV 2/5; 10/20] START criterion=gini, max_depth=24, n_estimators=900............\n",
      "[CV 2/5; 10/20] END criterion=gini, max_depth=24, n_estimators=900;, score=0.885 total time=   0.7s\n",
      "[CV 3/5; 10/20] START criterion=gini, max_depth=24, n_estimators=900............\n",
      "[CV 3/5; 10/20] END criterion=gini, max_depth=24, n_estimators=900;, score=0.902 total time=   0.7s\n",
      "[CV 4/5; 10/20] START criterion=gini, max_depth=24, n_estimators=900............\n",
      "[CV 4/5; 10/20] END criterion=gini, max_depth=24, n_estimators=900;, score=0.870 total time=   0.7s\n",
      "[CV 5/5; 10/20] START criterion=gini, max_depth=24, n_estimators=900............\n",
      "[CV 5/5; 10/20] END criterion=gini, max_depth=24, n_estimators=900;, score=0.865 total time=   0.7s\n",
      "[CV 1/5; 11/20] START criterion=gini, max_depth=17, n_estimators=300............\n",
      "[CV 1/5; 11/20] END criterion=gini, max_depth=17, n_estimators=300;, score=0.870 total time=   0.2s\n",
      "[CV 2/5; 11/20] START criterion=gini, max_depth=17, n_estimators=300............\n",
      "[CV 2/5; 11/20] END criterion=gini, max_depth=17, n_estimators=300;, score=0.877 total time=   0.2s\n",
      "[CV 3/5; 11/20] START criterion=gini, max_depth=17, n_estimators=300............\n",
      "[CV 3/5; 11/20] END criterion=gini, max_depth=17, n_estimators=300;, score=0.890 total time=   0.2s\n",
      "[CV 4/5; 11/20] START criterion=gini, max_depth=17, n_estimators=300............\n",
      "[CV 4/5; 11/20] END criterion=gini, max_depth=17, n_estimators=300;, score=0.882 total time=   0.2s\n",
      "[CV 5/5; 11/20] START criterion=gini, max_depth=17, n_estimators=300............\n",
      "[CV 5/5; 11/20] END criterion=gini, max_depth=17, n_estimators=300;, score=0.873 total time=   0.2s\n",
      "[CV 1/5; 12/20] START criterion=entropy, max_depth=11, n_estimators=500.........\n",
      "[CV 1/5; 12/20] END criterion=entropy, max_depth=11, n_estimators=500;, score=0.890 total time=   0.3s\n",
      "[CV 2/5; 12/20] START criterion=entropy, max_depth=11, n_estimators=500.........\n",
      "[CV 2/5; 12/20] END criterion=entropy, max_depth=11, n_estimators=500;, score=0.885 total time=   0.3s\n",
      "[CV 3/5; 12/20] START criterion=entropy, max_depth=11, n_estimators=500.........\n",
      "[CV 3/5; 12/20] END criterion=entropy, max_depth=11, n_estimators=500;, score=0.905 total time=   0.3s\n",
      "[CV 4/5; 12/20] START criterion=entropy, max_depth=11, n_estimators=500.........\n",
      "[CV 4/5; 12/20] END criterion=entropy, max_depth=11, n_estimators=500;, score=0.870 total time=   0.3s\n",
      "[CV 5/5; 12/20] START criterion=entropy, max_depth=11, n_estimators=500.........\n",
      "[CV 5/5; 12/20] END criterion=entropy, max_depth=11, n_estimators=500;, score=0.870 total time=   0.3s\n",
      "[CV 1/5; 13/20] START criterion=entropy, max_depth=3, n_estimators=1100.........\n",
      "[CV 1/5; 13/20] END criterion=entropy, max_depth=3, n_estimators=1100;, score=0.775 total time=   0.7s\n",
      "[CV 2/5; 13/20] START criterion=entropy, max_depth=3, n_estimators=1100.........\n",
      "[CV 2/5; 13/20] END criterion=entropy, max_depth=3, n_estimators=1100;, score=0.767 total time=   0.6s\n",
      "[CV 3/5; 13/20] START criterion=entropy, max_depth=3, n_estimators=1100.........\n",
      "[CV 3/5; 13/20] END criterion=entropy, max_depth=3, n_estimators=1100;, score=0.800 total time=   0.6s\n",
      "[CV 4/5; 13/20] START criterion=entropy, max_depth=3, n_estimators=1100.........\n",
      "[CV 4/5; 13/20] END criterion=entropy, max_depth=3, n_estimators=1100;, score=0.787 total time=   0.7s\n",
      "[CV 5/5; 13/20] START criterion=entropy, max_depth=3, n_estimators=1100.........\n",
      "[CV 5/5; 13/20] END criterion=entropy, max_depth=3, n_estimators=1100;, score=0.767 total time=   0.6s\n",
      "[CV 1/5; 14/20] START criterion=entropy, max_depth=16, n_estimators=800.........\n",
      "[CV 1/5; 14/20] END criterion=entropy, max_depth=16, n_estimators=800;, score=0.880 total time=   0.6s\n",
      "[CV 2/5; 14/20] START criterion=entropy, max_depth=16, n_estimators=800.........\n",
      "[CV 2/5; 14/20] END criterion=entropy, max_depth=16, n_estimators=800;, score=0.905 total time=   0.6s\n",
      "[CV 3/5; 14/20] START criterion=entropy, max_depth=16, n_estimators=800.........\n",
      "[CV 3/5; 14/20] END criterion=entropy, max_depth=16, n_estimators=800;, score=0.907 total time=   0.6s\n",
      "[CV 4/5; 14/20] START criterion=entropy, max_depth=16, n_estimators=800.........\n",
      "[CV 4/5; 14/20] END criterion=entropy, max_depth=16, n_estimators=800;, score=0.873 total time=   0.6s\n",
      "[CV 5/5; 14/20] START criterion=entropy, max_depth=16, n_estimators=800.........\n",
      "[CV 5/5; 14/20] END criterion=entropy, max_depth=16, n_estimators=800;, score=0.882 total time=   0.7s\n",
      "[CV 1/5; 15/20] START criterion=gini, max_depth=22, n_estimators=800............\n",
      "[CV 1/5; 15/20] END criterion=gini, max_depth=22, n_estimators=800;, score=0.890 total time=   0.5s\n",
      "[CV 2/5; 15/20] START criterion=gini, max_depth=22, n_estimators=800............\n",
      "[CV 2/5; 15/20] END criterion=gini, max_depth=22, n_estimators=800;, score=0.875 total time=   0.5s\n",
      "[CV 3/5; 15/20] START criterion=gini, max_depth=22, n_estimators=800............\n",
      "[CV 3/5; 15/20] END criterion=gini, max_depth=22, n_estimators=800;, score=0.897 total time=   0.6s\n",
      "[CV 4/5; 15/20] START criterion=gini, max_depth=22, n_estimators=800............\n",
      "[CV 4/5; 15/20] END criterion=gini, max_depth=22, n_estimators=800;, score=0.870 total time=   0.6s\n",
      "[CV 5/5; 15/20] START criterion=gini, max_depth=22, n_estimators=800............\n",
      "[CV 5/5; 15/20] END criterion=gini, max_depth=22, n_estimators=800;, score=0.868 total time=   0.6s\n",
      "[CV 1/5; 16/20] START criterion=gini, max_depth=2, n_estimators=700.............\n",
      "[CV 1/5; 16/20] END criterion=gini, max_depth=2, n_estimators=700;, score=0.762 total time=   0.5s\n",
      "[CV 2/5; 16/20] START criterion=gini, max_depth=2, n_estimators=700.............\n",
      "[CV 2/5; 16/20] END criterion=gini, max_depth=2, n_estimators=700;, score=0.743 total time=   0.5s\n",
      "[CV 3/5; 16/20] START criterion=gini, max_depth=2, n_estimators=700.............\n",
      "[CV 3/5; 16/20] END criterion=gini, max_depth=2, n_estimators=700;, score=0.785 total time=   0.5s\n",
      "[CV 4/5; 16/20] START criterion=gini, max_depth=2, n_estimators=700.............\n",
      "[CV 4/5; 16/20] END criterion=gini, max_depth=2, n_estimators=700;, score=0.782 total time=   0.5s\n",
      "[CV 5/5; 16/20] START criterion=gini, max_depth=2, n_estimators=700.............\n",
      "[CV 5/5; 16/20] END criterion=gini, max_depth=2, n_estimators=700;, score=0.750 total time=   0.5s\n",
      "[CV 1/5; 17/20] START criterion=gini, max_depth=13, n_estimators=400............\n",
      "[CV 1/5; 17/20] END criterion=gini, max_depth=13, n_estimators=400;, score=0.895 total time=   0.2s\n",
      "[CV 2/5; 17/20] START criterion=gini, max_depth=13, n_estimators=400............\n",
      "[CV 2/5; 17/20] END criterion=gini, max_depth=13, n_estimators=400;, score=0.877 total time=   0.3s\n",
      "[CV 3/5; 17/20] START criterion=gini, max_depth=13, n_estimators=400............\n",
      "[CV 3/5; 17/20] END criterion=gini, max_depth=13, n_estimators=400;, score=0.895 total time=   0.2s\n",
      "[CV 4/5; 17/20] START criterion=gini, max_depth=13, n_estimators=400............\n",
      "[CV 4/5; 17/20] END criterion=gini, max_depth=13, n_estimators=400;, score=0.880 total time=   0.2s\n",
      "[CV 5/5; 17/20] START criterion=gini, max_depth=13, n_estimators=400............\n",
      "[CV 5/5; 17/20] END criterion=gini, max_depth=13, n_estimators=400;, score=0.858 total time=   0.2s\n",
      "[CV 1/5; 18/20] START criterion=gini, max_depth=24, n_estimators=600............\n",
      "[CV 1/5; 18/20] END criterion=gini, max_depth=24, n_estimators=600;, score=0.882 total time=   0.4s\n",
      "[CV 2/5; 18/20] START criterion=gini, max_depth=24, n_estimators=600............\n",
      "[CV 2/5; 18/20] END criterion=gini, max_depth=24, n_estimators=600;, score=0.885 total time=   0.4s\n",
      "[CV 3/5; 18/20] START criterion=gini, max_depth=24, n_estimators=600............\n",
      "[CV 3/5; 18/20] END criterion=gini, max_depth=24, n_estimators=600;, score=0.892 total time=   0.4s\n",
      "[CV 4/5; 18/20] START criterion=gini, max_depth=24, n_estimators=600............\n",
      "[CV 4/5; 18/20] END criterion=gini, max_depth=24, n_estimators=600;, score=0.870 total time=   0.4s\n",
      "[CV 5/5; 18/20] START criterion=gini, max_depth=24, n_estimators=600............\n",
      "[CV 5/5; 18/20] END criterion=gini, max_depth=24, n_estimators=600;, score=0.865 total time=   0.4s\n",
      "[CV 1/5; 19/20] START criterion=gini, max_depth=14, n_estimators=900............\n",
      "[CV 1/5; 19/20] END criterion=gini, max_depth=14, n_estimators=900;, score=0.882 total time=   0.6s\n",
      "[CV 2/5; 19/20] START criterion=gini, max_depth=14, n_estimators=900............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 19/20] END criterion=gini, max_depth=14, n_estimators=900;, score=0.895 total time=   0.7s\n",
      "[CV 3/5; 19/20] START criterion=gini, max_depth=14, n_estimators=900............\n",
      "[CV 3/5; 19/20] END criterion=gini, max_depth=14, n_estimators=900;, score=0.897 total time=   0.7s\n",
      "[CV 4/5; 19/20] START criterion=gini, max_depth=14, n_estimators=900............\n",
      "[CV 4/5; 19/20] END criterion=gini, max_depth=14, n_estimators=900;, score=0.873 total time=   0.7s\n",
      "[CV 5/5; 19/20] START criterion=gini, max_depth=14, n_estimators=900............\n",
      "[CV 5/5; 19/20] END criterion=gini, max_depth=14, n_estimators=900;, score=0.870 total time=   0.7s\n",
      "[CV 1/5; 20/20] START criterion=gini, max_depth=27, n_estimators=1100...........\n",
      "[CV 1/5; 20/20] END criterion=gini, max_depth=27, n_estimators=1100;, score=0.880 total time=   0.8s\n",
      "[CV 2/5; 20/20] START criterion=gini, max_depth=27, n_estimators=1100...........\n",
      "[CV 2/5; 20/20] END criterion=gini, max_depth=27, n_estimators=1100;, score=0.885 total time=   0.8s\n",
      "[CV 3/5; 20/20] START criterion=gini, max_depth=27, n_estimators=1100...........\n",
      "[CV 3/5; 20/20] END criterion=gini, max_depth=27, n_estimators=1100;, score=0.895 total time=   0.8s\n",
      "[CV 4/5; 20/20] START criterion=gini, max_depth=27, n_estimators=1100...........\n",
      "[CV 4/5; 20/20] END criterion=gini, max_depth=27, n_estimators=1100;, score=0.875 total time=   0.7s\n",
      "[CV 5/5; 20/20] START criterion=gini, max_depth=27, n_estimators=1100...........\n",
      "[CV 5/5; 20/20] END criterion=gini, max_depth=27, n_estimators=1100;, score=0.875 total time=   0.8s\n",
      "Best score: 0.8895\n",
      "Best parameters set:\n",
      "\tcriterion: entropy\n",
      "\tmax_depth: 16\n",
      "\tn_estimators: 800\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    classifier = ensemble.RandomForestClassifier(n_jobs=-1) \n",
    "    \n",
    "    # 更改搜索空间\n",
    "    param_grid = {\n",
    "        \"n_estimators\": np.arange(100, 1500, 100), \n",
    "        \"max_depth\": np.arange(1, 31),\n",
    "        \"criterion\": [\"gini\", \"entropy\"] \n",
    "    }\n",
    "    \n",
    "    # 随机参数搜索\n",
    "    model = model_selection.RandomizedSearchCV( \n",
    "        estimator=classifier,\n",
    "        param_distributions=param_grid, \n",
    "        n_iter=20,\n",
    "        scoring=\"accuracy\", \n",
    "        verbose=10,\n",
    "        n_jobs=1, \n",
    "        cv=5\n",
    "    )\n",
    "   \n",
    "# 使用网格搜索对象 model 拟合数据，寻找最佳参数组合\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    print(f\"Best score: {model.best_score_}\") \n",
    "    print(\"Best parameters set:\")\n",
    "    \n",
    "    best_parameters = model.best_estimator_.get_params() \n",
    "    \n",
    "    for param_name in sorted(param_grid.keys()):\n",
    "        print(f\"\\t{param_name}: {best_parameters[param_name]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21561464",
   "metadata": {},
   "source": [
    "> **使用```RandomizedSearchCV```和```GridSearchCV```这两种方法，你可以为各种模型找到最优参数，只要它们有拟合和预测功能**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af88ff4",
   "metadata": {},
   "source": [
    "## 使用sklearn-optimize库实现超参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385b5f3c",
   "metadata": {},
   "source": [
    "## 超参数优化|随机森林\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0648d1f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
